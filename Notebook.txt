#######################
# Uploaded 2021-06-10 as historical record and a place for me to find code snippets if needed.
# This file contains a mix of R and bash commands, some relevant output, and my running commentary as I worked through the analysis for the paper.
# (Think of this as the poor man's textfile version of a jupyter notebook.)
#######################

# Analysis Notes for Zapus Husbandy Paper 2020-07-15

# Making Map of trapping area using R

County:	Worcester County
Latitude:	42.462592
Longitude:	-71.6439571
GNIS ID:	606358

###

library("ggmap")

stamen_map_1 <- get_stamenmap(bbox = c(left = -81, bottom = 38, right = -51, top = 48), zoom = 6, maptype = "terrain-background")
ggmap(stamen_map_1)

# Need to zoom in further, bigger zoom numbers = more detail, "terrain" includes roads, etc - more than just background
stamen_map_1 <- get_stamenmap(bbox = c(left = -71.65, bottom = 42, right = -71.09, top = 42.56), zoom = 11, maptype = "terrain")
ggmap(stamen_map_1)

# Zoom in even further
stamen_map_1 <- get_stamenmap(bbox = c(left = -71.664, bottom = 42.42, right = -71.624, top = 42.48), zoom = 13, maptype = "terrain")
ggmap(stamen_map_1)

# Dialed in. Note that going to higher zoom level makes label text too small for small picture
stamen_map_1 <- get_stamenmap(bbox = c(left = -71.67, bottom = 42.445, right = -71.62, top = 42.485), zoom = 14, maptype = "terrain")
ggmap(stamen_map_1)

# Also plotted and saved using "toner-lite" and some other styles.



####### Notes 7/20/2020 -- binomial test for checking sex ratio of Zapus pups in captivity in R

> binom.test(x=c(81,43), p=0.5, alternative="two.sided")

	Exact binomial test

data:  c(81, 43)
number of successes = 81, number of trials = 124, p-value = 0.0008203
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.5625302 0.7364144
sample estimates:
probability of success
             0.6532258

### we have stat. sig. deviation from the expected male:female ratio

### Looking in this book chapter for help on statistics:  Wilson, K., & Hardy, I. (2002). Statistical analysis of sex ratios: An introduction. In I. Hardy (Ed.), Sex Ratios: Concepts and Research Methods (pp. 48-92). Cambridge: Cambridge University Press. doi:10.1017/CBO9780511542053.004
# Looks like binomial test is the right way to go, also need to check whether the distribution matches a binomial (I suspect it doesn't)
# Try this in R: https://towardsdatascience.com/one-proportion-and-goodness-of-fit-test-in-r-and-by-hand-8c7997013c84

# make file "fraction_male.txt", count number of instances of each fraction male, save to new file

awk '{a[$0]++}END{for(i in a){print i, a[i]}}' fraction_male.txt > abs_freq_fraction_male.txt

0.5 4
0.8 2
0.833333333 1
0.25 1
0.75 2
0.333333333 2
0 6
1 13

# need to make comparator binomial distribution -- use rbinom() to generate random samples using p=0.5 for litter sizes matching actual data:
awk '{a[$0]++}END{for(i in a){print i, a[i]}}' litter-size.txt | sort -k1 > litter-size-count.txt
litter_size count
1 1
2 3
3 7
4 8
5 8
6 4

### 7/21/2020 ### 
# want to make 'expected' distribution, make vector of litter sizes, manually add headers.
litter_size <- as.vector(read.table("litter-size.txt"))
# read into R
litter_size_counts <- read.table("litter-size-count.txt", header=TRUE)
# sample from binomial distribution:
test <-c()  #set up null vector
for (i in 1:nrow(litter_size_counts)) {test <- c(test,rbinom(litter_size_counts$Count[i],litter_size_counts$Size[i],0.5))}  #write the values to vector .... but do this another way.....

## use list of litter sizes to start: "litter_size"
 
# initialize test data frame of correct size
test <- data.frame(matrix(ncol = 2, nrow = 31)) 

# set the column names for size of litter, number of males (to be generated by rbinom, and fraction male to be calculated
colnames(test) <-c("Size","Male")  

# populate values
for (i in 1:nrow(litter_size)) {test[i,] <- c(litter_size$V1[i],rbinom(1,litter_size$V1[i],0.5))}  

# make new column of fraction male
test$Fraction=test$Male/test$Size

# plot histogram of simulated data
hist(test$Fraction, breaks = i)

# get my actual data (fraction male)
frac_male <- as.vector(read.table("fraction_male.txt"))

# plot histogram of actual data
hist(frac_male$V1, breaks = i)

## don't think this is going to work since I am combining a bunch of trials of different sizes; won't be able to use chi-square (?) since I'm creating a continuous-like data set
## but the central limit theorum should apply: https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html

#make q-q plots using ggplot:
p <- ggplot(frac_male, aes(sample = frac_male$V1))
p + stat_qq() + stat_qq_line()

p1 <- ggplot(test, aes(sample = test$Fraction))
p1 + stat_qq() + stat_qq_line()

# can't tell much from this, visually

# Try Shapiro-Wilk test for normality --- "The null-hypothesis of this test is that the population is normally distributed. Thus, if the p value is less than the chosen alpha level, then the null hypothesis is rejected and there is evidence that the data tested are not normally distributed."

# this is my real data.... reject null, conclude that it is not normally distributed

shapiro.test(frac_male$V1)  

	Shapiro-Wilk normality test

data:  frac_male$V1
W = 0.79957, p-value = 5.069e-05


# this is my simulated data.... fail to reject null, conclude normally distributed
shapiro.test(test$Fraction)

	Shapiro-Wilk normality test

data:  test$Fraction
W = 0.947, p-value = 0.1289

# make density plot of these data, using lines() to overlay the second onto the first:
plot(density(test$Fraction),xlim=c(0,1))
lines(density(frac_male$V1), col="red")

# save simulated test data to txt file:
write.table(test, "simulated_litter_data_table.txt")

# made density curve plot for saving:
plot(density(test$Fraction), main = "Litter Sex Ratio Density Curves ", xlab="Fraction Male, n = 31 Litters\nRed is Observed, Black is Simulated")
lines(density(frac_male$V1), col="red")

# note that it will be a lot of work to plot histogram and density plots in such a way that they are scaled to view easily (need two y axes)

# make larger simulation of data (try 10000 times 31 litters) to make histogram

test_sim <- data.frame(matrix(ncol = 10001, nrow = 31))  # make only rows of simulated data, first row will be litter size
colnames(test_sim) <-c("Size")				#make column name for first column
for (i in 1:nrow(litter_size)) {test_sim[i,] <- c(litter_size$V1[i],rbinom(10000,litter_size$V1[i],0.5))} # generate simulated number of males per litter
test_sim_frac = test_sim/test_sim$Size    # divide by litter size to get fraction male
test_sim_frac$Size <- NULL  # get rid of first column to leave only simulated data
hist(unlist(test_sim_frac), breaks = i, col="gray", main = "Histogram 10,000 Simulated Sets of 31 Litters ", xlab="Fraction Male, n = 10,000 * 31 Litters")  # look at histogram, note that unlist() converts to table to vector for hist()
density(unlist(test_sim_frac), main = "Density Curve of 10,000 Simulated Sets of 31 Litters ", xlab="Fraction Male, n = 10,000 * 31 Litters")

# want to try Shapiro Wilk test on larger amount of simulated data; not that the R command can only handle up to 5000 data points....
# simulate 100 * 31 litters for testing
test_sim_100 <- data.frame(matrix(ncol = 101, nrow = 31))  # make only rows of simulated data, first row will be litter size
colnames(test_sim_100) <-c("Size")				#make column name for first column
for (i in 1:nrow(litter_size)) {test_sim_100[i,] <- c(litter_size$V1[i],rbinom(100,litter_size$V1[i],0.5))} # generate simulated number of males per litter
test_sim_100_frac = test_sim_100/test_sim_100$Size    # divide by litter size to get fraction male
test_sim_100_frac$Size <- NULL  # get rid of first column to leave only simulated data
shapiro.test(unlist(test_sim_100_frac))

	Shapiro-Wilk normality test

data:  unlist(test_sim_100_frac)
W = 0.95994, p-value < 2.2e-16

############ Note that given the underlying small litter sizes and non-continuous nature of this, it comes back as non-normal, which we see from the density curves and histogram

# We can probably make our own cutoff values.... (?) from the table of 10,000 samples, how many of them have greater than or equal to 19 litters with fraction male of 1 or 0?
# try transposing table to use rowSums to count them
test_sim_frac_transpose <- t(test_sim_frac)

# make new data frame to hold counts of zeros and ones
test_sim_frac_t_count <- data.frame(matrix(ncol = 3, nrow = 10000))
colnames(test_sim_frac_t_count) <-c("Zero","One","Sum")

# count zeros and ones per row, put into new data frame, sum them
test_sim_frac_t_count$Zero <- rowSums(test_sim_frac_transpose == "0")
test_sim_frac_t_count$One <- rowSums(test_sim_frac_transpose == "1")
test_sim_frac_t_count$Sum = test_sim_frac_t_count$Zero + test_sim_frac_t_count$One
head(test_sim_frac_t_count)
  Zero One Sum
1    4   2   6
2    2   3   5
3    0   3   3
4    3   5   8
5    0   4   4
6    4   4   8
hist(test_sim_frac_t_count$Sum, col="gray", main = "Number of All Male and All Female Litters\nDistribution from 10,000 Simulated Sets of 31 Litters", xlab="Number of All Male or All Female Litters ", xlim=c(0,20))

# write output to file 
write.table(test_sim_frac_t_count$Sum, "distribution_10K.txt")  # note has header line and line numbers...
# sort in bash
sort -hrk2 distribution_10K.txt | head
"9672" 14
"1580" 14
"7726" 13
"5739" 13
"4193" 13
"3278" 13
"3236" 13
"2664" 13
"9773" 12


# note that we only ever got up to 14 single-sex litters in 10,000 tries


###### will repeat with 10 million tries to see if we can get into the distribution
test_sim_10M <- data.frame(matrix(ncol = 10000001, nrow = 31))  # make only rows of simulated data, first row will be litter size
colnames(test_sim_10M) <-c("Size")				#make column name for first column
for (i in 1:nrow(litter_size)) {test_sim_10M[i,] <- c(litter_size$V1[i],rbinom(10000000,litter_size$V1[i],0.5))} # generate simulated number of males per litter  # need to run this differently, without indexing, perhaps
# trying to rewrite the above for loop
size <- as.vector(litter_size$V1)  # make vector of litter_sizes
matrix_out <-matrix(ncol=10000000,nrow=31)

# checking times to run small versions, using smaller matrices
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(10,size[i],0.5)})
   user  system elapsed
  0.003   0.000   0.003
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(100,size[i],0.5)})
   user  system elapsed
  0.004   0.000   0.003
> system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(1000,size[i],0.5)})
   user  system elapsed
  0.005   0.002   0.010
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(10000,size[i],0.5)})
   user  system elapsed
  0.019   0.001   0.020
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(100000,size[i],0.5)})
   user  system elapsed
  0.174   0.009   0.182
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(1000000,size[i],0.5)})
   user  system elapsed
  1.772   0.089   1.861
system.time(for (i in 1:31) {matrix_out[i,] <- rbinom(10000000,size[i],0.5)})  ## this worked
   user  system elapsed
 19.635   0.600  20.237

# now need to divide by litter size to get fraction male
#matrix_out_fraction <- t(matrix_out) / size  #this is also fast .... but doesn't divide in the right way!!!
matrix_out_fraction <- matrix_out / size  
max(matrix_out_fraction)  # this works, have to transpose for row counting
[1] 1

matrix_out_fraction <- t(matrix_out_fraction)

# too slow indexing in dataframe, make vectors for counts
# want to count across 31 rows to get number of 0 and 1 fraction male

test_sim_10M_count_zero <- rowSums(matrix_out_fraction == "0")  # counting takes a while, output looks good
test_sim_10M_count_one <- rowSums(matrix_out_fraction == "1")
test_sim_10M_count_sum <- test_sim_10M_count_zero + test_sim_10M_count_one

mean(test_sim_10M_count_sum)
[1] 5.874894

# looks good, try histogram
hist(test_sim_10M_count_sum, col="gray", main = "Number of All Male and All Female Litters\nDistribution from 10 Million Simulated Sets of 31 Litters", xlab="Number of All Male or All Female Litters ", xlim=c(0,20))

# write output to file 
write.table(test_sim_10M_count_sum, "distribution_10M.txt")  # note has header line and line numbers...
# sort in bash
sort -hrk2 distribution_10M.txt | head

"4754161" 17
"3688740" 17
"2750290" 17
"1818114" 17
"1496089" 17
"1307740" 17
"9854498" 16
"9506948" 16
"9437440" 16
"8975810" 16

##### Greatest number of single-sex litters is 17, no instance of 19 single-sex litters in 10M, thus  p<1e-7

# also make histogram of observed litter size and get mean size, which is 4
hist(unlist(litter_size$V1), col="gray", main = "Histogram of Litter Size ", xlab="Number of Weaned Pups per Litter, n = 31 Litters", xlim=c(0,8))  # look at histogram, note that unlist() converts to table to vector for hist()
mean(litter_size$V1)
[1] 4

# make histogram of litter size of those litters that are all male or all female
# put litter size and fraction male data into file:
nano litter-size_frac-male.txt
awk '{if ($2==0 || $2==1) print $0}' litter-size_frac-male.txt  ## works and there are 19 of these litters, now write only litter size to file
4	1
5	1
5	0
6	1
5	0
5	1
4	1
5	1
6	0
3	0
3	1
4	1
5	1
1	0
3	1
3	1
4	0
2	1
3	1

awk '{if ($2==0 || $2==1) print $1}' litter-size_frac-male.txt > litter-size_all-M-or-F.txt

# read into R to plot histogram and get 
litter_size_all_M_or_F <- as.vector(read.table("litter-size_all-M-or-F.txt"))

mean(litter_size_all_M_or_F$V1)
[1] 4

### saving session to disk taking way too long, partial file is 0.5Gb...way to much in memory, etc.
# have saved some results to disk, full matrix-out file is too big to worry about writing to disk; can rerun if needed.

############# try 10 million simulation one more time with sex ratio of 0.6532258 to see if using the observed sex ratio gives more single-sex litters in the simulation

size <- as.vector(litter_size$V1)  # make vector of litter_sizes
matrix_out_065 <-matrix(ncol=10000000,nrow=31)
system.time(for (i in 1:31) {matrix_out_065[i,] <- rbinom(10000000,size[i],0.6532258)})  ## using observed male ratio

# now need to divide by litter size to get fraction male
matrix_out_065_fraction <- matrix_out_065 / size  
# transpose for row counting 
matrix_out_065_fraction <- t(matrix_out_065_fraction)

# want to count across 31 rows to get number of 0 and 1 fraction male

test_sim_10M_065_count_zero <- rowSums(matrix_out_065_fraction == "0")  # counting takes a while, output looks good
test_sim_10M_065_count_one <- rowSums(matrix_out_065_fraction == "1")
test_sim_10M_065_count_sum <- test_sim_10M_065_count_zero + test_sim_10M_065_count_one

mean(test_sim_10M_065_count_sum)
[1] 7.766457


# looks good, try histograms
hist(test_sim_10M_065_count_sum, col="gray", main = "Number of Single-Sex Litters per 31 Simulated Litters at p=0.6532 for Males\nDistribution from 10 Million Simulated Sets of 31 Litters ", xlab="Number of Single-Sex Litters ", xlim=c(0,20))

hist(unlist(matrix_out_065_fraction), breaks = i, col="gray", main = "Histogram of 10 Million Simulated Sets of 31 Litters\np=0.6532 of Male", xlab="Fraction Male, n = 10,000 * 31 Litters")

# write output to file 
write.table(test_sim_10M_065_count_sum, "distribution_10M_065.txt")  # note has header line and line numbers...
# sort in bash
sort -hrk2 distribution_10M_065.txt | head

"7791190" 20
"6602256" 20
"3954506" 20
"2627045" 20
"9897376" 19
"947821" 19
"9270947" 19
"8720940" 19
"8319843" 19
"8188682" 19

# there is some probability, find out what:
# test with this:
awk '{if ($2 >= 20) sum=sum+1}END{print sum}' distribution_10M_065.txt
4
# awk '{if ($2 >= 19) sum=sum+1}END{print sum}' distribution_10M_065.txt
27

# So the probability of at least 19 same-sex litters occuring (of 31 litters), if the sex ratio is 0.6532258, is 27/1e7, or 0.0000027, or p = 2.7x10^-6


############## 7/24/2020 ######### Working on additional statistics focused on breeding

# export filemaker database as comma separated file ".csv" without notes field and having removed all commas

#have 266 pairings, of which 2 were actual births to wild-caught females that came in pregnant, and one was an accidental mating when pups were left too long in a cage
#so have 263 attempted pairings
# column headers in text file with my addition of column number
head -n1 Zapus_Database_export20200724.csv

Breeding_Female(1)	Breeding_Male(2)	Order_Paired(3)	Date_Paired(4)	Date_Separated(5)	Earliest_Due(6)	Latest_Due(7)	Pairing_Successful(8)	Number_of_Pups_Weaned(9)	Birth_Date(10)	Target_Wean_Date(11)	Wean_Date(12)	Separate_Immediately(13)

# get number of successful pairings
awk -F, 'NR>1{print $8}' Zapus_Database_export20200724.csv | grep -e YES | wc -l
      41   # note two were caught pregnant
# get number of litters weaned
awk -F, 'NR>1{if ($9>0) sum=sum+1}END{print sum}' Zapus_Database_export20200724.csv
32  # NOTE, HAVE ONE MORE THAN USED IN SEX RATIO ANALYSIS, was missing litter born at MIT to B10 on 8/25/19. She had one female and 5 males in her surviving 6 pups. REDO BELOW


############## redoing sex ratio analysis with updated litter numbers 7/24/2020
# binomial test to check for deviation from p=0.5 of male, have 86 males and 44 females

binom.test(x=c(86,44), p=0.5, alternative="two.sided")

	Exact binomial test

data:  c(86, 44)
number of successes = 86, number of trials = 130, p-value = 0.0002895
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.5733696 0.7421617
sample estimates:
probability of success
             0.6615385

# update litter_size.txt with new litter,
# want to make 'expected' distribution, make vector of litter sizes
litter_size <- as.vector(read.table("litter-size.txt"))

# update fraction_male.txt with new litter,
# get my actual data (fraction male)
frac_male <- as.vector(read.table("fraction_male.txt"))

# simulate 10 million sets of 32 litters with my litter size distribution
size <- as.vector(litter_size$V1)  # make vector of litter_sizes
matrix_out <-matrix(ncol=10000000,nrow=32)
system.time(for (i in 1:32) {matrix_out[i,] <- rbinom(10000000,size[i],0.5)})

# now need to divide by litter size to get fraction male
matrix_out_fraction <- matrix_out / size  
max(matrix_out_fraction)  

# this works, have to transpose for row counting
matrix_out_fraction <- t(matrix_out_fraction)

# want to count across 32 rows to get number of 0 and 1 fraction male

test_sim_10M_05_count_zero <- rowSums(matrix_out_fraction == "0")  # counting takes a while, output looks good
test_sim_10M_05_count_one <- rowSums(matrix_out_fraction == "1")
test_sim_10M_05_count_sum <- test_sim_10M_05_count_zero + test_sim_10M_05_count_one

mean(test_sim_10M_05_count_sum)
[1] 5.90594

# looks good, try histograms
hist(test_sim_10M_05_count_sum, col="gray", main = "Number of Single-Sex Litters per 32 Simulated Litters at p=0.6615 for Males\nDistribution from 10 Million Simulated Sets of 32 Litters ", xlab="Number of Single-Sex Litters ", xlim=c(0,20))

hist(unlist(matrix_out_fraction), breaks = i, col="gray", main = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.5 of Male", xlab="Fraction Male, n = 10M * 32 Litters")

# write output to file 
write.table(test_sim_10M_05_count_sum, "distribution_10M_05.txt")  # note has header line and line numbers...
# sort in bash
sort -hrk2 distribution_10M_05.txt | head

"9748494" 18
"8324172" 17
"7019762" 17
"5929881" 17
"4079519" 17
"9930759" 16
"9249104" 16
"9163730" 16
"904572" 16

# never got a set of litters in which 19 were same sex, therefore p<1e-7 

### now repeat above using actual male - female ratio of 0.6615385

# simulate 10 million sets of 32 litters with my litter size distribution
matrix_out_066 <-matrix(ncol=10000000,nrow=32)
system.time(for (i in 1:32) {matrix_out_066[i,] <- rbinom(10000000,size[i],0.6615385)})

# now need to divide by litter size to get fraction male
matrix_out_066_fraction <- matrix_out_066 / size  
max(matrix_out_066_fraction)  
[1] 1

# this works, have to transpose for row counting
matrix_out_066_fraction <- t(matrix_out_066_fraction)

# want to count across 32 rows to get number of 0 and 1 fraction male

test_sim_10M_066_count_zero <- rowSums(matrix_out_066_fraction == "0")  # counting takes a while, output looks good
test_sim_10M_066_count_one <- rowSums(matrix_out_066_fraction == "1")
test_sim_10M_066_count_sum <- test_sim_10M_066_count_zero + test_sim_10M_066_count_one

mean(test_sim_10M_066_count_sum)
[1] 8.066372

# looks good, try histograms
hist(test_sim_10M_066_count_sum, col="gray", main = "Number of Single-Sex Litters per 32 Simulated Litters at p=0.6615 for Males\nDistribution from 10 Million Simulated Sets of 32 Litters ", xlab="Number of Single-Sex Litters ", xlim=c(0,20), breaks = i)

hist(unlist(matrix_out_066_fraction), breaks = i, col="gray", main = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.6615 of Male", xlab="Fraction Male, n = 10M * 32 Litters")

# write output to file 
write.table(test_sim_10M_066_count_sum, "distribution_10M_066.txt")  # note has header line and line numbers...
# get max number of single sex litters:
max(test_sim_10M_066_count_sum)
[1] 21

# sort in bash
sort -hrk2 distribution_10M_066.txt | head
9880102" 21
"9426065" 21
"8912258" 21
"907612" 20
"5073147" 20
"4895570" 20
"4600320" 20
"4343500" 20
"980608" 19
"9572855" 19

# so there is some probability of getting 19 or more in 10 million, find out what:
# test with this:
awk '{if ($2 >= 19) sum=sum+1}END{print sum}' distribution_10M_066.txt
82

# So the probability of at least 19 same-sex litters occuring (of 31 litters), if the sex ratio is 0.6615385, is 82/1e7, or 0.0000082, or p = 8.2x10^-6
# What about only males or only females? I got 6 all female litters and 13 all male litters.
# Write out number of all-female litters (test_sim_10M_066_count_zero) and all-male litters (test_sim_10M_066_count_one) to process with awk
write.table(test_sim_10M_066_count_zero, "distribution_10M_all_female_066.txt")
write.table(test_sim_10M_066_count_one, "distribution_10M_all_male_066.txt")
mean(test_sim_10M_066_count_zero)
[1] 1.10211
mean(test_sim_10M_066_count_one)
[1] 6.964262
awk '{if ($2 >= 6) sum=sum+1}END{print sum}' distribution_10M_all_female_066.txt  ##### probability of getting at least 6 all female litters at 66% male= 0.0002243
2243
awk '{if ($2 >= 13) sum=sum+1}END{print sum}' distribution_10M_all_male_066.txt   ##### probability of getting at least 13 all male litters at 66% male= 0.0089502
89502

write.table(test_sim_10M_05_count_zero, "distribution_10M_all_female_05.txt")
write.table(test_sim_10M_05_count_one, "distribution_10M_all_male_05.txt")
awk '{if ($2 >= 6) sum=sum+1}END{print sum}' distribution_10M_all_female_05.txt  ##### probability of getting at least 6 all female litters at 50% male= 0.0573288
573288
awk '{if ($2 >= 13) sum=sum+1}END{print sum}' distribution_10M_all_male_05.txt   ##### probability of getting at least 13 all male litters at 50% male= 0.0574319
574319

## plot histogram of actual data
hist(frac_male$V1, col="gray", main = "Histogram of Weaned Litter Size", xlab="Fraction Male, n = 32 Litters", breaks = i, ylim=c(0,14))


########### 8/1/2020 ##############
# Finishing work with 7/24/2020 export of Zapus Database
# Save exported .csv file as "Zapus_Database_export20200724.xlsx" for further work, see analysis tab in this file.

# Use excel to get longest and shortest possible gestation lengths for all births with known pairing and separation dates
# Put into this file: "gest_length_bounds.txt" for import into R -- I want to make a histogram stacking the intervals of possible lengths
gest_max_min <- read.table("gest_length_bounds.txt", header=TRUE)
x <- data.frame(matrix(ncol = 39, nrow = 37))   # NOTE, this is too wide, but non-issue for what I want to do
for (i in 1:nrow(gest_max_min)) {x[i,] <- c(seq(gest_max_min$Min[i],gest_max_min$Max[i]),rep(NA,39-length(seq(gest_max_min$Min[i],gest_max_min$Max[i]))))}   # fill in numbers of possible days for each range, pad with NA's at end
hist(unlist(x), breaks=i, col="gray", main = "Histogram of Possible Gestation Lengths", xlab="Possible Days Gestation")
median(na.omit(unlist(x)))
1] 18


############# 8/25/2020 ###############
# Need to plot time series data -- nest box temperature
nbtemp <- read.table("2016-04-28 hibernation nest box temp for Husbandry Paper.csv", sep=",", header=TRUE)  ## read in data
library(lubridate)    # use lubridate to convert factor to date
nbtemp$Date.and.Time <- lubridate::ymd_hms(nbtemp$Date.and.Time, tz = "US/Central")   ### have to specify time zone so it converts properly
str(nbtemp) ### checks and looks good

## now try plotting, looks like probe 1 was another mouse that didn't hibernate for as long, use probe 2

ggplot(data = nbtemp, aes(x = Date.and.Time, y = Probe.2.Temperature)) + geom_line(color = "blue", size = 0.5)
# this works, try also plotting reference temperature, look here for plotting more than one series per chart: http://www.sthda.com/english/articles/32-r-graphics-essentials/128-plot-time-series-data-using-ggplot/
library(tidyr)
library(dplyr)

nbtempgather <- nbtemp %>% select(Date.and.Time, Probe.2.Temperature, Reference.2.Temperature) %>% gather(key = "temp", value = "value", -Date.and.Time)
head(nbtempgather, 3)
        Date.and.Time                temp value
1 2016-04-29 00:39:36 Probe.2.Temperature 14.00
2 2016-04-29 00:40:06 Probe.2.Temperature 14.75
3 2016-04-29 00:40:36 Probe.2.Temperature 16.00

ggplot(nbtempgather, aes(x = Date.and.Time, y = value)) + geom_line(aes(color = temp), size = 0.5) + scale_color_manual(values=c("blue", "red")) + theme_minimal()

## this works but have messy data in reference temperature, looks like a few zeros and one -256; set them to NA

nbtempgather$value[nbtempgather$value <= 0] <- NA  ## this works, needs a little further cleanup
nbtempgather$value[nbtempgather$value <= 2] <- NA
nbtempgather$value[nbtempgather$value >= 30] <- NA

ggplot(nbtempgather, aes(x = Date.and.Time, y = value)) + geom_line(aes(color = temp), size = 0.5) + scale_color_manual(values=c("blue", "red")) + theme_minimal()

# This works fine, but need to reorder the factors ("Reference.2.Temperature","Probe.2.Temperature") so that the last one gets plotted on top

nbtempgather$temp <- factor(nbtempgather$temp, c("Reference.2.Temperature","Probe.2.Temperature"))

ggplot(nbtempgather, aes(x = Date.and.Time, y = value)) + geom_line(aes(color = temp), size = 0.5) + scale_color_manual(values=c("gray", "red")) + theme_minimal()

# now looks good, figuring out how to set axes
min <- as.POSIXct("2016-04-30 00:00:00", tz = "US/Central")   ## create a limit ... making the POSIXct date works, but this format doesn't work with as.Data as needed by ggplot

# lay aside for now

############### 8/26/2020 ##############
# use add = TRUE to plot multiple histograms on same plot (https://www.dataanalytics.org.uk/plot-two-overlapping-histograms-on-one-chart-in-r/)
# from tutorial, make transparent colors:
c1 <- rgb(173,216,230,max = 255, alpha = 80, names = "lt.blue")
c2 <- rgb(255,192,203, max = 255, alpha = 120, names = "lt.pink")

hist(gest_max_min$Min, xlim = c(0,40), col = c1)  # plot lower limit of gestation time
hist(gest_max_min$Max, xlim = c(0,40), col = c2, add = TRUE, breaks = 10)  # plot upper limits of gestation time

## now repeat code from 8/1/2020 to allow overlay of these onto the original histogram
x <- data.frame(matrix(ncol = 39, nrow = 37))   # NOTE, this is too wide, but non-issue for what I want to do
for (i in 1:nrow(gest_max_min)) {x[i,] <- c(seq(gest_max_min$Min[i],gest_max_min$Max[i]),rep(NA,39-length(seq(gest_max_min$Min[i],gest_max_min$Max[i]))))}   # fill in numbers of possible days for each range, pad with NA's at end
hist(unlist(x), breaks=i, col="gray", main = "Histogram of Possible Gestation Lengths", xlab="Possible Days Gestation")
hist(gest_max_min$Max, col = c2, add = TRUE, breaks = 20)
hist(gest_max_min$Min, col = c1, add = TRUE, breaks = 20) # use this order to overlay pink on top of blue
# this works ok; saved file
# if want to make better, would need to subtract away from below lower limits and above upper limits
write.table(unlist(x), "gest_length_list_for_counts.txt") ## write out list of possible gestation lengths in days, in single column
# use awk to get counts of number of days
awk 'NR>1{if ($2 != "NA") print $2}' gest_length_list_for_counts.txt | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort -hk1
1 1
2 1
3 3
4 3
5 5
6 5
7 5
8 6
9 6
10 6
11 7
12 7
13 9
14 12
15 16
16 23
17 32
18 35
19 31
20 24
21 14
22 12
23 6
24 4
25 4
26 4
27 3
28 3
29 3
30 2
31 2
32 2
33 2
34 2
35 2
36 1
37 1
38 1
39 1
# ... plan to just do subtraction in excel to require less thinking....
# get counts for max and min bounds from "gest_length_bounds.txt"

awk 'NR>1{print $1}' gest_length_bounds.txt | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort -hk1  ## column 1 is Max
16 1
17 1
18 4
19 7
20 10
21 2
22 6
23 2
26 1
29 1
35 1
39 1

awk 'NR>1{print $2}' gest_length_bounds.txt | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort -hk1  ## column 2 is min
3 2
5 2
8 1
11 1
13 2
14 3
15 4
16 7
17 10
18 4

# now manually make excel sheet "gest_length_histogram_subtraction.xlsx" and subtract off out-of-bound lengths from the frequency distribution according to the frequency of the max and min, giving these remaining: 
16	9
17	27
18	33
19	25
20	11
# put back into R
cut_gest_list <- rep(16:20, c(9,27,33,25,11))
# can't get the bars to align well using hist(), move to ggplot geom_histogram()...
cut_gest_frame <- as.data.frame(cut_gest_list)  # move data from vector to data frame
# plot using ggplot, boundary setting centers ticks under the bars
ggplot(data=cut_gest_frame, aes(x = cut_gest_frame$cut_gest_list)) + geom_histogram(col="darkgray", binwidth=1, boundary = -0.5)  # this works, can move forward with this if needed.


############### 8/27/2020 #####################
#been doing a lot of figure-making in GraphPad Prism
#try out GLM on max weight attained (as percent of starting weight) during hibernation experiments
#make table in max_weight.txt:
#import
max_weight <- read.table("max_weight.txt", header = TRUE)
# run glm
test <- glm(formula = Max_Wt ~ Photoperiod + Temp, gaussian, max_weight)
summary(test)


Call:
glm(formula = Max_Wt ~ Photoperiod + Temp, family = gaussian,
    data = max_weight)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-40.647   -2.560    1.142    7.385   21.585

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)
(Intercept)      145.9181    14.5498  10.029 1.15e-09 ***
Photoperiodshort  36.2547     7.5936   4.774 9.11e-05 ***
Temp              -1.8179     0.6913  -2.630   0.0153 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for gaussian family taken to be 205.4846)

    Null deviance: 20336.0  on 24  degrees of freedom
Residual deviance:  4520.7  on 22  degrees of freedom
AIC: 208.89

Number of Fisher Scoring iterations: 2

## try again, excluding the 7 C animal that died; new table: max_wt_no_dead.txt
max_wt_no_dead <- read.table("max_wt_no_dead.txt", header = TRUE)
test_no_dead <- glm(formula = Max_Wt ~ Photoperiod + Temp, gaussian, max_wt_no_dead)
summary(test_no_dead)


Call:
glm(formula = Max_Wt ~ Photoperiod + Temp, family = gaussian,
    data = max_wt_no_dead)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-29.9312   -2.9262    0.7044    4.4738   23.0688

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)
(Intercept)      159.2695    11.7311  13.577 7.24e-12 ***
Photoperiodshort  34.7712     5.8789   5.915 7.17e-06 ***
Temp              -2.4855     0.5598  -4.440 0.000227 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for gaussian family taken to be 122.6664)

    Null deviance: 20229  on 23  degrees of freedom
Residual deviance:  2576  on 21  degrees of freedom
AIC: 188.33

Number of Fisher Scoring iterations: 2



## Not much change caused by removing the dead outlier from 7 deg C group.
## Interpretation: effect size of short photoperiod is large, "causing" increase in max body weight
## and body weight increases as temperature falls, by around 1.8% body weight per degree C.
## Both coefficients are significant.

## Given correlation between body weight and max food consumption, 
## also want to look at relative effects of body mass, temp, and photoperiod on food consumption 
## -- here, might also want to look at something like AUC, perhaps using the food consumption data
## normalized to body weight.  Maybe easiest to calculate total food consumed over the first 6 weeks.
## Took a look at this AUC idea in prism and 

# for right now, try glm on max food consumption as determined by body wt, photoperiod, and temp
# make new table here: food_max_wt.txt
# load into R
food <- read.table("food_max_wt.txt", header = TRUE)
test_food <- glm(formula = Food ~ Max_Wt + Photoperiod + Temp, gaussian, food)
summary(test_food)


Call:
glm(formula = Food ~ Max_Wt + Photoperiod + Temp, family = gaussian,
    data = food)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-5.5849  -1.1526   0.3852   0.9474   4.1980

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)
(Intercept)        6.6257     4.3439   1.525 0.142113
Max_Wt             0.4654     0.1737   2.679 0.014034 *
Photoperiodshort  -3.3466     1.7753  -1.885 0.073329 .
Temp              -0.4815     0.1109  -4.343 0.000286 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for gaussian family taken to be 5.037081)

    Null deviance: 366.37  on 24  degrees of freedom
Residual deviance: 105.78  on 21  degrees of freedom
AIC: 117.01

Number of Fisher Scoring iterations: 2


## Here, looks like Temperature and max weight are significant effects, with photoperiod
## essentially there; note negative coefficient on photoperiod and that weight and photoperiod are correlated
# try again leaving out photoperiod:
test_food_no_photoperiod <- glm(formula = Food ~ Max_Wt + Temp, gaussian, food)
summary(test_food_no_photoperiod)

Call:
glm(formula = Food ~ Max_Wt + Temp, family = gaussian, data = food)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-5.3255  -1.0896  -0.2117   1.1993   5.0411

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   9.5274     4.2914   2.220  0.03702 *
Max_Wt        0.2223     0.1229   1.809  0.08421 .
Temp         -0.4280     0.1132  -3.781  0.00103 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for gaussian family taken to be 5.621756)

    Null deviance: 366.37  on 24  degrees of freedom
Residual deviance: 123.68  on 22  degrees of freedom
AIC: 118.92

Number of Fisher Scoring iterations: 2

## This model is worse, note greater AIC; intercept had to soak up effects of max weight and photoperiod

################## 8/28/2020 #############
# Got data for torpor times, etc. Now trying GLM analysis of pre-hibernation food consumption data to understand the relative role of weight,
# temperature, individual mouse, (and to a lesser extent), photoperiod and housing location.  At least those are my expectations for importance.
# Data are compiled in "Hibernation Food and Weight Analysis for Husbandry Paper.xlsx" and in pre_hib_food_vs_wt.txt.
# Column headers: Animal	Weight	Food	Temp	Photoperiod	Location

# Import into R:
pre_hib_food_vs_weight <- read.table("pre_hib_food_vs_wt.txt", header = TRUE)

# switching to lm() instead of glm() because I'm using a linear model and lm() gives R square and F stat.
lm_pre_hib_food_wt <- lm(formula = Food ~ Weight*Temp + Animal + Photoperiod + Location, pre_hib_food_vs_weight)
summary(lm_pre_hib_food_wt)

Call:
lm(formula = Food ~ Weight * Temp + Animal + Photoperiod + Location,
    data = pre_hib_food_vs_weight)

Residuals:
    Min      1Q  Median      3Q     Max
-8.4393 -0.5820 -0.0610  0.5956  8.0877

Coefficients: (3 not defined because of singularities)
                   Estimate Std. Error t value Pr(>|t|)
(Intercept)      -14.036859   1.886013  -7.443 3.36e-13 ***
Weight             1.126964   0.084331  13.364  < 2e-16 ***
Temp               0.913936   0.124872   7.319 7.89e-13 ***
AnimalM22          0.849283   0.600729   1.414 0.157943
AnimalM23         -1.465063   0.407471  -3.596 0.000350 ***
AnimalM24          0.771151   0.638420   1.208 0.227550
AnimalM25          1.318248   0.421858   3.125 0.001863 **
AnimalM26          2.155307   0.405677   5.313 1.51e-07 ***
AnimalM27         -0.749674   0.421175  -1.780 0.075579 .
AnimalM28          2.289821   0.476716   4.803 1.96e-06 ***
AnimalM29         -1.601074   0.405035  -3.953 8.62e-05 ***
AnimalM31         -2.460993   0.401407  -6.131 1.57e-09 ***
AnimalM32         -1.505311   0.688356  -2.187 0.029134 *
AnimalM34         -0.762257   0.411133  -1.854 0.064214 .
AnimalM35         -0.768275   0.405526  -1.895 0.058628 .
AnimalM36          0.313601   0.494472   0.634 0.526178
AnimalM37          0.226529   0.629755   0.360 0.719189
AnimalM39         -0.299800   0.420724  -0.713 0.476376
AnimalM40         -0.992272   0.419915  -2.363 0.018438 *
AnimalM43         -2.214817   0.435845  -5.082 4.98e-07 ***
AnimalM47          2.168859   0.609848   3.556 0.000405 ***
AnimalM54          2.630604   0.401397   6.554 1.19e-10 ***
AnimalM55         -0.076507   0.551698  -0.139 0.889752
AnimalM56          0.934760   0.402050   2.325 0.020399 *
AnimalM57         -0.214848   0.428723  -0.501 0.616456
AnimalM58         -0.160294   0.477037  -0.336 0.736971
AnimalM59                NA         NA      NA       NA
Photoperiodshort         NA         NA      NA       NA
Locationcolony           NA         NA      NA       NA
Weight:Temp       -0.053093   0.006068  -8.750  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.555 on 612 degrees of freedom
Multiple R-squared:  0.721,	Adjusted R-squared:  0.7092
F-statistic: 60.84 on 26 and 612 DF,  p-value: < 2.2e-16

### note, R squared here is much better if include individual animals; photoperiod and colony don't add anything
### the interaction between Weight and Temp makes things work out that temp has no effect at ~17 g weight, but
### this effect rises from about 0.5 g food eaten as you go from 20 to 7 C, to adding about 9 g food eaten at 30 g body weight.
### can be seen in slope of scatter plots of body wt x food eaten at different temps.

# redo regression for Max Weight from yesterday using lm()
test_lm <- lm(formula = Max_Wt ~ Photoperiod + Temp, max_weight)

Call:
lm(formula = Max_Wt ~ Photoperiod + Temp, data = max_weight)

Residuals:
    Min      1Q  Median      3Q     Max
-40.647  -2.560   1.142   7.385  21.585

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)
(Intercept)      145.9181    14.5498  10.029 1.15e-09 ***
Photoperiodshort  36.2547     7.5936   4.774 9.11e-05 ***
Temp              -1.8179     0.6913  -2.630   0.0153 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 14.33 on 22 degrees of freedom
Multiple R-squared:  0.7777,	Adjusted R-squared:  0.7575
F-statistic: 38.48 on 2 and 22 DF,  p-value: 6.551e-08

# This one also has reasonable explanatory value despite small numbers. Will have to decide if useful to include either of 
# these regressions in the paper.

##################### 8/31/2020 ##################
# for food consumption regression, added age at experiment start, dam, and sire, and a litter designation to the "pre_hib_food_vs_wt.txt" table (also in GLM tab of spreadsheet).
# try repeating with these variables
pre_hib_food_vs_weight <- read.table("pre_hib_food_vs_wt.txt", header = TRUE)
lm_pre_hib_food_wt <- lm(formula = Food ~ Weight*Temp*Age + Photoperiod + Sire*Dam + Location, pre_hib_food_vs_weight)

> summary(lm_pre_hib_food_wt)

Call:
lm(formula = Food ~ Weight * Temp * Age + Photoperiod + Location +
    Dam + Sire, data = pre_hib_food_vs_weight)

Residuals:
    Min      1Q  Median      3Q     Max
-8.6644 -0.7006 -0.1060  0.6910  8.6740

Coefficients: (5 not defined because of singularities)
                   Estimate Std. Error t value Pr(>|t|)
(Intercept)      -5.0421143  6.2068336  -0.812 0.416902
Weight            1.1029963  0.2932045   3.762 0.000185 ***
Temp              1.3983376  0.3984729   3.509 0.000482 ***
Age              -0.0016513  0.0193558  -0.085 0.932039
Photoperiodshort -1.7976380  0.2789348  -6.445 2.32e-10 ***
Locationcolony   -2.8348505  0.6656231  -4.259 2.37e-05 ***
Damfemale_13     -0.2691320  0.3805582  -0.707 0.479705
Damfemale_18     -2.6563058  0.5127360  -5.181 2.99e-07 ***
Damfemale_19     -5.5202137  1.2095646  -4.564 6.05e-06 ***
Damfemale_20     -3.1533823  0.7346724  -4.292 2.05e-05 ***
Damfemale_33     -4.2194899  1.4053109  -3.003 0.002785 **
Damfemale_A10    -2.1306566  1.2661575  -1.683 0.092921 .
Damfemale_A5     -4.7463475  1.2303174  -3.858 0.000126 ***
Siremale_3               NA         NA      NA       NA
Siremale_4               NA         NA      NA       NA
Siremale_A13             NA         NA      NA       NA
Siremale_A2              NA         NA      NA       NA
Siremale_A6              NA         NA      NA       NA
Weight:Temp      -0.0746068  0.0210842  -3.539 0.000432 ***
Weight:Age       -0.0006226  0.0009471  -0.657 0.511196
Temp:Age         -0.0026469  0.0013215  -2.003 0.045615 *
Weight:Temp:Age   0.0001288  0.0000709   1.816 0.069820 .
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.692 on 622 degrees of freedom
Multiple R-squared:  0.664,	Adjusted R-squared:  0.6553
F-statistic: 76.81 on 16 and 622 DF,  p-value: < 2.2e-16

## note that the coefficients assigned to dam and sire change depending on which order these variables are listed in the model.
## doesn't look like we are getting much useful information about the individual dams and sires from this, just some coefficients
## needed to make the model work. The effect is dominated by the Weight*Temp interaction

## try again with litter designation instead of dam and sire, note that age effect will be included in litter.
## model is quite robust to specification, in that food consumption is dominated by Weight, Temp, & Weight*Temp effects
## Report this model in manuscript:

> lm_pre_hib_food_wt <- lm(formula = Food ~ Weight*Temp*Photoperiod + Location + Litter, pre_hib_food_vs_weight)
> summary(lm_pre_hib_food_wt)

Call:
lm(formula = Food ~ Weight * Temp * Photoperiod + Location +
    Litter, data = pre_hib_food_vs_weight)

Residuals:
    Min      1Q  Median      3Q     Max
-9.4168 -0.7673 -0.1022  0.7597  8.9327

Coefficients: (2 not defined because of singularities)
                               Estimate Std. Error t value Pr(>|t|)
(Intercept)                  -10.991819   3.522343  -3.121 0.001888 **
Weight                         1.151620   0.176512   6.524 1.41e-10 ***
Temp                           0.585173   0.124570   4.698 3.24e-06 ***
Photoperiodshort               0.280075   2.588890   0.108 0.913885
Locationcolony                -1.080143   0.306312  -3.526 0.000452 ***
LitterB                        1.076284   0.271341   3.967 8.14e-05 ***
LitterC                       -0.339226   0.289665  -1.171 0.242006
LitterD                       -0.115605   0.282050  -0.410 0.682039
LitterE                        0.092480   0.314342   0.294 0.768702
LitterF                       -0.869526   0.467668  -1.859 0.063457 .
LitterG                        1.687346   0.431868   3.907 0.000104 ***
LitterH                        0.984698   0.321922   3.059 0.002317 **
Weight:Temp                   -0.044081   0.005811  -7.585 1.21e-13 ***
Weight:Photoperiodshort       -0.111869   0.136241  -0.821 0.411894
Temp:Photoperiodshort                NA         NA      NA       NA
Weight:Temp:Photoperiodshort         NA         NA      NA       NA
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.737 on 625 degrees of freedom
Multiple R-squared:  0.6445,	Adjusted R-squared:  0.6371
F-statistic: 87.15 on 13 and 625 DF,  p-value: < 2.2e-16

# I think we need to keep all of the above variables in the model: Weight, Temp, Photoperiod, Location, Litter.  Note that photoperiod effect is essential
# contained in the weights of the animals, so could drop if needed but leave in for now.  Minimal model still has good explanatory power, maybe report both
# either preemptively or if asked by the reviewers.

> lm_pre_hib_food_wt <- lm(formula = Food ~ Weight*Temp, pre_hib_food_vs_weight)
> summary(lm_pre_hib_food_wt)

Call:
lm(formula = Food ~ Weight * Temp, data = pre_hib_food_vs_weight)

Residuals:
    Min      1Q  Median      3Q     Max
-9.9392 -1.0666 -0.2334  0.9416 10.3151

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept) -12.983828   1.881850  -6.900 1.27e-11 ***
Weight        1.137591   0.087596  12.987  < 2e-16 ***
Temp          0.799651   0.108911   7.342 6.46e-13 ***
Weight:Temp  -0.051169   0.005243  -9.759  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.003 on 635 degrees of freedom
Multiple R-squared:  0.5193,	Adjusted R-squared:  0.517
F-statistic: 228.6 on 3 and 635 DF,  p-value: < 2.2e-16


##### now doing data analysis of expedata motion recordings for the 12/2017 breeder hibernation experiment
## batch export all channels to tab separated .txt file "export.txt", appending all to same file.
## note that 20180223.txt has bad time stamp data - don't include; renaming.

# concatanate using awk to skip headers:
head -n1 20171208.txt > combined_motion_data.txt    # write column headers to file
awk 'FNR>1 {print $0}' 201*.txt >> combined_motion_data.txt    # write all data to file without headers
wc -l 201*.txt  # check total lines
	48809 total
wc -l combined_motion_data.txt  # check resulting lines; difference is 25, using 26 files, should be missing 25 first lines so this is correct.
   48784 combined_motion_data.txt

# now import into R
# issue with Marker column ("line 45438 did not have 13 elements"); use awk to remove this column
awk -F \t 'BEGIN{OFS = "\t"}{print $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12}' combined_motion_data.txt > motion_data_no_marker.txt
motion <- read.table("motion_data_no_marker.txt", header = TRUE, sep = "\t")   # worked this time
# need to format DateTime column as datetime format, use lubridate package
motion$DateTime <- mdy_hms(motion$DateTime, tz = "US/Central")

#### also note that daylight saving time started on march 11 (looks like recording failed that week); we did not change the timers; may need
#### to adjust the time by one hour to match up the light cycle with the recorded time. We did not change the light cycle timers.

# now try plotting:
ggplot(data = motion, aes(x = DateTime, y = Motion_3)) + geom_line(color = "blue", size = 0.25)    # this works
# and with setting x axis using dates:
ggplot(data = motion, aes(x = DateTime, y = Deg_C_1)) + geom_line(color = "blue", size = 0.25) + xlim(c(as.POSIXct('2017-12-04 00:00:00', format = "%Y-%m-%d %H:%M:%S"),as.POSIXct('2017-12-24 00:00:00', format = "%Y-%m-%d %H:%M:%S")))

# this works for setting dates; can fill area under curve using geom_area()
# now try cleaning up motion sensor data:
test <- motion
test$Motion_3[test$Motion_3 < 0.5] <- 0
test$Motion_3[test$Motion_3 >= 0.5] <- 1

## have some duplicates in the data.... same date, duplicated times.. not sure what's going on. Will have to check original files. Also will probably have to plot 
# here are my duplicated dates:
awk -F \t '{print $1}' 201*.txt | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort -k3 | awk '{if ($3==2) print $1}' | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort
12/15/2017 13
12/16/2017 288
12/17/2017 288
12/18/2017 288
12/19/2017 288
12/20/2017 288
12/21/2017 288
12/22/2017 185
4/16/2018 84
4/17/2018 288
4/18/2018 288
4/19/2018 288
4/20/2018 180
6/3/2018 41
6/4/2018 288
6/5/2018 288
6/6/2018 288
6/7/2018 288
6/8/2018 160

Looks like this file (Data_12-29-2017...) has the same end date as the previous file (12/22/2017)... do have recorded the stop time, so can correct to within 1 minute if needed if this is correct, or use temperature baseline ... looks like recorded stop time is not the actual end time; probably ran out of buffer before.
4/27 overflow error looks like different data than previous week but uses the incorrect end datetime (?). Too bad don't have working photocell or could recover. Have about 94 hours of data and can use temp baseline to align timing.
6/15 overflow error, same as above. Have some photocell signal and about 112 hours (4.67 days) of data.
6/22 no error, have some photocell signal and almost 7 days of data.

Missing weeks ending:
2/23/2018  (omit because have about 9 hours only)
3/16/2018
4/6/2018

missing some days on each overflow error.

################## 9/1/2020 #####################

# use Excel sheet, Expedata, and exported data to figure out transitions and correct ending dates for data files ending 12/29/2017, 4/27/2018, and 6/15/2018.
# export corrected data via Expedata, append "_corrected_datetime" to filenames


# redo processing from above
# strip marker column:
awk -F \t 'BEGIN{OFS = "\t"}{print $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12}' combined_motion_data.txt > motion_data_no_marker.txt
# load into R
motion <- read.table("motion_data_no_marker.txt", header = TRUE, sep = "\t")   # worked this time
# need to format DateTime column as datetime format, use lubridate package
motion$DateTime <- mdy_hms(motion$DateTime, tz = "US/Central")

################# 9/2/2020 ######################
# plan for breeder hibernation data analysis:
# 1. Add NAs at the end of each recording to see if will properly graph gaps in R, strip Marker column
# 2. Check and correct shift of one hour occuring March 11 02:00 for daylight saving
# 3. Clean up bad motion sensor data (voltages out of range, etc)
# 4. Count activity by light/dark phase for each day, outputting number of samples light, number of samples dark, activity light, activity dark, average recorded temp for the day

## 1. make line to append in line_for_NAs.txt
# append to all files
for f in *.txt; do cat line_for_NAs.txt >> $f; done    # this worked
# manually add the appropriate next datetime to the end of each file

# combine all files for R import
# concatanate using awk to skip headers:
head -n1 20171208.txt > combined_motion_data.txt    # write column headers to file
awk 'FNR>1 {print $0}' 201*.txt >> combined_motion_data.txt    # write all data to file without headers
# strip marker column
awk -F \t 'BEGIN{OFS = "\t"}{print $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12}' combined_motion_data.txt > motion_data_no_marker.txt
motion <- read.table("motion_data_no_marker.txt", header = TRUE, sep = "\t")   # worked this time
# need to format DateTime column as datetime format, use lubridate package
motion$DateTime <- mdy_hms(motion$DateTime, tz = "US/Central")

# plot to check that NAs worked.... yes.
ggplot(data = motion, aes(x = DateTime, y = Motion_3)) + geom_line(color = "blue", size = 0.25)

## 2. Time Zone shift: occured during week with missing data, need to subtract one hour from all datetimes following march 11, try doing this in R using lubridate
# make sure can subtract hours:
testdate <- motion[1,1]
testdate
[1] "2017-12-04 13:38:54 CST"
str(testdate)
 POSIXct[1:1], format: "2017-12-04 13:38:54"
testdateminus <- testdate - hours(1)
testdateminus
[1] "2017-12-04 12:38:54 CST"

# this works, now apply to my "motion" dataframe, to all dates post March 11pa# make new dates for replacement
new_datetime <- as.data.frame(motion$DateTime - hours(
# assign date for comparision
changeover_date <- as.POSIXct('2018-03-11 02:00:00 CST')

# having a difficult time conditionally subtracting my hour from dataframe in R, to expedite will compile two sets (before and after March 11), then process the second and combine
# make lists of data files before and after DST changeover, files_beforeDST.txt and files_afterDST.txt
head -n1 20171208.txt > combined_motion_data_before.txt
head -n1 20171208.txt > combined_motion_data_after.txt
for f in $(cat files_beforeDST.txt); do awk 'FNR>1 {print $0}' ${f} >> combined_motion_data_before.txt; done
for f in $(cat files_afterDST.txt); do awk 'FNR>1 {print $0}' ${f} >> combined_motion_data_after.txt; done
# number of lines add up (note this included header row on the "after" data
# strip Marker column from both
awk -F \t 'BEGIN{OFS = "\t"}{print $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12}' combined_motion_data_before.txt > motion_data_no_marker_before.txt
awk -F \t 'BEGIN{OFS = "\t"}{print $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12}' combined_motion_data_after.txt > motion_data_no_marker_after.txt

# now back to R, process dates on on "after" file, bring back to shell
motion_afterDST <- read.table("motion_data_no_marker_after.txt", header = TRUE, sep = "\t")
# format DateTime column as datetime format, use lubridate package
motion_afterDST$DateTime <- mdy_hms(motion_afterDST$DateTime, tz = "US/Central")
# subtract one hour from all datetimes in this data (from 3/16 on....)
head(motion_afterDST$DateTime)
[1] "2018-03-16 11:33:18 CDT" "2018-03-16 11:38:18 CDT"
[3] "2018-03-16 11:43:18 CDT" "2018-03-16 11:48:18 CDT"
[5] "2018-03-16 11:53:18 CDT" "2018-03-16 11:58:18 CDT"
motion_afterDST$DateTime <- motion_afterDST$DateTime - hours(1)
head(motion_afterDST$DateTime)
[1] "2018-03-16 10:33:18 CDT" "2018-03-16 10:38:18 CDT"
[3] "2018-03-16 10:43:18 CDT" "2018-03-16 10:48:18 CDT"
[5] "2018-03-16 10:53:18 CDT" "2018-03-16 10:58:18 CDT"

# this worked, now export to text file with no row (e.g., "1", "2", etc) or column names
write.table(motion_afterDST, "motion_data_no_marker_after_subtractDST.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
# note that output date format is different that input format; will process the top half of the data the same way in R to make them match
# import into R
motion_before <- read.table("motion_data_no_marker_before.txt", header = TRUE, sep = "\t")
# process datetime
motion_before$DateTime <- mdy_hms(motion_before$DateTime, tz = "US/Central")
# write table, keeping header row
write.table(motion_before, "motion_data_no_marker_before_process_datetime.txt", sep = "\t", row.names = FALSE, col.names = TRUE)

# now concat with the first part of the data in bash
cat motion_data_no_marker_before_process_datetime.txt motion_data_no_marker_after_subtractDST.txt > motion_DST_corrected.txt

# NOTE: this file (motion_DST_corrected.txt) can now be used to compile daily stats, will try this using awk, but first...

## 3. Need to clean up bad motion sensor data before further processing
# bring entire table back into R and convert to dates
allmotion <- read.table("motion_DST_corrected.txt", header = TRUE, sep = "\t")
allmotion$DateTime <- ymd_hms(allmotion$DateTime, tz = "US/Central")            # note now different format than all the above work, since came from R

# draw some graphs to check motion sensor data; note that we really only care about motion channels 2, 3, 4, 5, and 9; animals 110, 104, 85, 103, and 106, respectively.
# as an aside, tried to install "breaks" package to get breaks_pretty() for ggplot2, but had non-zero exit status and didn't want to mess with it right now.
ggplot(data = allmotion, aes(x = DateTime, y = Motion_2)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_2, #110")
ggplot(data = allmotion, aes(x = DateTime, y = Motion_3)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_3, #104")
ggplot(data = allmotion, aes(x = DateTime, y = Motion_4)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_4, #85")
ggplot(data = allmotion, aes(x = DateTime, y = Motion_5)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_5, #103")
ggplot(data = allmotion, aes(x = DateTime, y = Motion_9)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_9, #106")

# saved plots in "motion_plots" directory
Need to clean up data from channels 2, 4, and 9.
Looks like for Motion 2 and 9, I can convert values > 3.5 to NA in R, but may have to manually clean up 4
# find date with bad motion data in Motion 4:
awk -F \t '{if($5<-0.1) print $0}' motion_DST_corrected.txt | awk '{print $1}' | uniq
"DateTime"
2017-12-15
2018-03-16
2018-03-17
2018-03-18
2018-03-19
2018-03-20
2018-03-21
2018-03-22
2018-03-23
2018-03-24
2018-03-25
2018-03-26
2018-03-27
2018-03-28
2018-03-29
2018-03-30

# note that there is only one single bad point on 12/15/2017; ignore for this purpose - exclude all points from 3/16 through 3/30

# make file for "cleaned" data
cp motion_DST_corrected.txt motion_DST_corrected_cleaned.txt

# now write NAs to the bad data in Motion_4 column; note the separators for awk...
# try this, note have to put space between the first two fields instead of a tab.
awk 'BEGIN{OFS="\t"}{if($1 == "2018-03-16" || $1 == "2018-03-17" || $1 == "2018-03-18" || $1 == "2018-03-19" || $1 == "2018-03-20" || $1 == "2018-03-21" || $1 == "2018-03-22" || $1 == "2018-03-23" || $1 == "2018-03-24" || $1 == "2018-03-25" || $1 == "2018-03-26" || $1 == "2018-03-27" || $1 == "2018-03-28" || $1 == "2018-03-29" || $1 == "2018-03-30") {print $1" "$2,$3,$4,$5,"NA",$7,$8,$9,$10,$11,$12,$13} else {print $0}}' motion_DST_corrected_cleaned.txt > motion_DST_corrected_cleaned4.txt

#check by graphing in R
allmotioncleaned4 <- read.table("motion_DST_corrected_cleaned4.txt", header=TRUE, sep="\t")
allmotioncleaned4$DateTime <- ymd_hms(allmotioncleaned4$DateTime, tz = "US/Central")
ggplot(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_4, #85")

# looks good

# do other two channels, try in R
# set any voltages above 3.5 to NA in the two problem channesl
allmotioncleaned4$Motion_2[allmotioncleaned4$Motion_2 >= 3.5] <- NA
allmotioncleaned4$Motion_9[allmotioncleaned4$Motion_9 >= 3.5] <- NA
# plot to make sure worked correctly
ggplot(data = allmotioncleaned4, aes(x = DateTime, y = Motion_2)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_2, #110")
ggplot(data = allmotioncleaned4, aes(x = DateTime, y = Motion_9)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_9, #106")

# these also look good.
# save cleaned table to file "motion_DST_correct_cleaned429.txt"

# Now need to figure out how to add up activity measurements per day (as defined by light cycle (07:36 - 15:36)), probably try this in AWK
# Planning to use awk program. 

# Write trial file using Motion_4, converting time to seconds:
sed 's/:/ /g' motion_DST_correct_cleaned429.txt | awk 'NR>1{print $1, $2*3600+$3*60+$4, $8}' > prepped_motion4.txt  ## sed removes colons, making more columns for awk; awk prints date, time in seconds, and the desired motion channel

# need cutoffs:
# Lights off:     15:36:00 = 15*3600+36*60+0 = 56160
# Lights on:      07:36:00 = 7*3600+36*60+0  = 27360

# writing awk script to get daily activity (motion_by_day.awk)
# this is now working, test how many "days" reported are not actually the same day (during transition between weeks or data loss)
awk -f motion_by_day.awk prepped_motion4.txt | sed 's/-/ /g' | awk '{if(($6-$3) !=1) i=i+1}END{print i}'
11
# looks like 11 instances of "bad" transitions
# check number of dates in data:
awk '{print $1}' prepped_motion4.txt | uniq | wc -l
     178

# check number of days in output:
awk -f motion_by_day.awk prepped_motion4.txt | wc -l
     171
# looks like have problems at 7 transitions

## new plan, use string of NAs across end of each file to mark new day
# make new version of motion_DST_correct_cleaned429.txt file, adding column of seconds
sed 's/:/ /g' motion_DST_correct_cleaned429.txt | awk 'BEGIN{getline; print "Date", "Seconds",$2, $3,$4, $5, $6, $7, $8, $9, $10, $11, $12}NR>1{print $1, $2*3600+$3*60+$4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15}' > prepped_motion429.txt

# now write a new "Photo" column, based on seconds elapsed, to specify light or dark cycle (note as of 9/8/2020, redoing this for the first two weeks)
awk 'BEGIN{getline;print $0, "Photo"}{if ($2 >= 56160 || $2 < 27360) {print $0, "Dark"} else {print $0, "Light"}}' prepped_motion429.txt > prepped_motion429_photo.txt
# make new version of awk script (motion_by_photoperiod.awk) to get activity by day and by photoperiod

awk -f motion_by_photoperiod.awk prepped_motion429_photo.txt | head -n5

start_date	end_date	motion_dark	motion_count_dark	motion_light	motion_count_lighttotal_motion	total_motion_count
Start	2017-12-04	0	0	2	24	2	24
2017-12-04	2017-12-05	121	192	0	96	121	288
2017-12-05	2017-12-06	108	192	0	96	108	288
2017-12-06	2017-12-07	114	192	0	96	114	288

## first partial day is a little funny, but rest generally looks ok.
# check transitions between recordings:
awk -f motion_by_photoperiod.awk prepped_motion429_photo.txt | sed 's/-/ /g' | awk 'BEGIN{OFS="\t"}NR>1{if($6-$3 !=1) print $1"-"$2"-"$3,$4"-"$5"-"$6, $6 - $3}'

Start Day	End Day		Diffence of Days
Start-2017-12	04-0-0	-12
2017-12-28	2018-01-02	-26
2018-01-31	2018-02-01	-30
2018-02-15	2018-02-23	8
2018-02-28	2018-03-01	-27
2018-03-08	2018-03-16	8
2018-04-19	2018-04-22	3
2018-04-25	2018-04-27	2
2018-04-30	2018-05-01	-29
2018-05-31	2018-06-01	-30
2018-06-12	2018-06-15	3 

# Figure out gap length between consecutive recordings:
awk 'BEGIN{prev=0}{if ($2 - prev != 300) {print $2 - prev; prev = $2}}' prepped_motion429_photo.txt | awk '{a[$0]++}END{for(i in a){print i, a[i]}}' | sort -h
-86100 17
-85800 153
-9283 1
-8003 1
0 1
107 1
195 1
240 1
600 24225
790 1
824 1
883 1
940 1
956 1
1104 1
1194 1
1215 1
1226 1
1229 1
1261 1
1477 1
1791 1
1844 1
1969 1
2016 1
2103 1
3575 1
9073 1
32822 1
49134 1

# Now get those that are not divisible by 300 seconds (% is modulo)
awk 'BEGIN{prev=0; prevdate=0}{if (($2 - prev)%300 != 0) {print prevdate, $1, $2 - prev; prev = $2; prevdate = $1}}' prepped_motion429_photo.txt
0 2017-12-04 49134 1
2017-12-04 2017-12-08 -6105 1
2017-12-08 2017-12-15 -4884 1
2017-12-15 2017-12-22 18315 1
2017-12-22 2018-01-02 -17927 1
2018-01-02 2018-01-05 -2231 1
2018-01-05 2018-01-12 9291 1
2018-01-12 2018-01-19 7803 1
2018-01-19 2018-01-26 -10506 1
2018-01-26 2018-02-02 7261 1
2018-02-02 2018-02-09 -3023 1
2018-02-09 2018-02-23 -503 1
2018-02-23 2018-03-02 -6271 1
2018-03-02 2018-03-16 -2356 1
2018-03-16 2018-03-23 -4296 1
2018-03-23 2018-04-06 25775 1
2018-04-06 2018-04-13 -12244 1
2018-04-13 2018-04-22 3407 1
2018-04-22 2018-04-27 -16483 1
2018-04-27 2018-05-04 9640 1
2018-05-04 2018-05-11 7783 1
2018-05-11 2018-05-18 -4310 1
2018-05-18 2018-05-25 -12076 1
2018-05-25 2018-06-01 -2674 1
2018-06-01 2018-06-08 12240 1
2018-06-08 2018-06-15 6722 

# use this modulo method, plus checking to see if date changed, to add a break between days/recordings, but not at midnight
# this is working; will need to output data for all 5 animals of interest.

################### 9/3/2020 #######################
## Thoughts on next steps:
# 1. Get activity data quantification for first week (16/8) and rest of recording (8/16); adjust awk script to do so
# 2. Make activity data figures showing first week of activity (w/light cycle), plus second week (first week in dark), maybe week leading up to first time found torpids.
# 3. Decide how to report quantification of activity data for above and total activity data
# 4. Make figures of overall activity monitoring for whole run, possibly plot w/weights & food consumption
# 5. Stats/analysis of activity, food consumption, weight: correlation between time active and food consumption? or between some measure of light or dark activity and food consumption?, other correlations?

## 1. What date did we change breeder hibernation experiment chamber to (8L/16D) and 7 Deg C?  
# changed on 12/8/2017; set temp lower at 2:00 pm, lights went off earlier at 15:36 to start long light cycle; so the day ending 12/9/17 is the first full day at 16D/8L.
# light cycle breaks for long days (from 20171208.txt):
awk -F \t '{print $1,$10,$11}' 20171208.txt | less

12/4/2017 18:03:54 20.418 2.466678	on
12/4/2017 18:08:54 20.25 0.463679	off

12/5/2017 02:03:54 20.98 0.4634446	off
12/5/2017 02:08:54 20.14 2.469178	on

# it appears that it's changing around 02:06:00 and 18:06:00, same 6 minute offset from actual time.
# need transition points in seconds for getting awk script quantification:
# 	02:06:00	= 	7560 seconds
#	18:06:00	=	65160 seconds
# make new version of awk script for the first week: "motion_by_photoperiod_first_week.awk"
# keep only first week (through early onset of dark cycle on 12/8/2017 at 15:36 -- this is line 1177; keep through line 1177 (last line of light)
# keep rest starting on line 1178 (first line of dark on 12/8/2017) through end, for rest of analysis.
awk 'NR<=1177{print $0}' prepped_motion429_photo.txt > prepped_motion429_photo_first_week.txt      # use this new file for first week analysis with updated awk script
awk 'BEGIN{getline;print $0}{if(NR>1177){print $0}}' prepped_motion429_photo.txt > prepped_motion429_photo_second_week-end.txt     # use this new file with original awk script for rest of quantification

# use these files to output quantification results to ./motion_quant_results/

# example command, have to change column number in awk script for each one:
awk -f motion_by_photoperiod_first_week.awk prepped_motion429_photo_first_week.txt > motion_quant_results/results_first_week_channel_9.txt

# example command, have to change column number in awk script for each one:
awk -f motion_by_photoperiod.awk prepped_motion429_photo_second_week-end.txt > ./motion_quant_results/results_rest_channel_9.txt

# compiled output data into excel file for further analysis in excel and prism regarding weights, food consumption, and activity.

## 2. Export first two weeks (appended together) from Expedata of motion for 6 animals to make figure: "First_2_Weeks_12-8_12-15_appended_good_motion.txt"
# see excel file "Breeder Hibernation Experiment Dates Torpid.xlsx" for details on which channels.


## working a few scatterplots of activity vs. food consumption, zero out all negative food consumptions; working in Excel and Graphpad Prism
# scatterplots of food vs activity are fine; note that 110 never hibernated, so could use as control.
# also made a plot of the breeder hibernation experiment with weight, food consumption, activity, etc.
# This graph looks awesome but note that GraphPad doesn't leave gaps in missing dates; will probably have to add these myself or plot in R if want to use this.

########### 9/8/2020 ######################

# Need to plot some activity data in R by range of date, giving a couple of options: 1) get the axis limits to work by inputting date limit in R, or 2) just extract the range of dates to plot, then plot the whole range.
# Will use mouse 85 in Motion channel 4, plot thusly:
ggplot(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_4, #85, Cleaned Data")
# need to add limits to x axis by date; try this first in R as will be more convenient if it works. 
# see here for how to do this: https://ggplot2.tidyverse.org/reference/scale_date.html, and try this:

ggplot(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4)) + geom_line(size = 0.25) + theme_minimal() + labs(title = "Motion_4, #85, Cleaned Data") + scale_x_datetime(limits=c(as.POSIXct("2017-12-04 15:36:00"),as.POSIXct("2017-12-08 07:36:00")))

# which works, can add breaks, etc.
# will need to add photoperiod to graph, probably using the flag I made in awk script ... 
# using text files: "prepped_motion429_photo_first_week.txt" and "prepped_motion429_photo_second_week-end.txt", compile column of Light or Dark and convert it to numeric for plotting in R (dark = 1, light = 0)
# have to fix the "Light" or "Dark" for the first week since I didn't deal with the longer days when processing on 9/2/2020.
# cutoffs are > 65160 seconds is dark and < 7560 seconds is light, same as in "motion_by_photoperiod_first_week.awk"

awk 'BEGIN{getline;print $0}{if ($2 >= 65160 || $2 < 7560) {$14="Dark"; print $0} else {$14="Light"; print $0}}' prepped_motion429_photo_first_week.txt > prepped_motion429_photo_first_week_correct.txt   
# no errors, check by piping into grep
# now compile column for R import:

awk 'FNR>1{if($14=="Dark"){print "1"}else if($14=="Light"){print "0"} else {print "error"}}' prepped_motion429_photo_first_week_correct.txt > prepped_motion429_photoperiod_column.txt
awk 'FNR>1{if($14=="Dark"){print "1"}else if($14=="Light"){print "0"} else {print "error"}}' prepped_motion429_photo_second_week-end.txt >> prepped_motion429_photoperiod_column.txt

# length is correct: 48809 observations
# import into R, put into cleaned table of motion data
IsDark <- (read.table("prepped_motion429_photoperiod_column.txt", header = FALSE))
allmotioncleaned4$IsDark <- IsDark$V1
str(allmotioncleaned4)
'data.frame':	48809 obs. of  13 variables:
 $ DateTime : POSIXct, format: "2017-12-04 13:38:54" "2017-12-04 13:43:54" ...
 $ Motion   : num  4.6 4.61 4.6 4.6 4.6 ...
 $ Motion_2 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Motion_3 : num  3.35013 3.34966 -0.12102 -0.05633 0.00914 ...
 $ Motion_4 : num  3.3014 3.3017 0.0102 0.0113 0.0129 ...
 $ Motion_5 : num  3.3314 3.3322 0.011 0.0126 0.012 ...
 $ Volts_6  : num  3.3859 3.3886 3.385 0.011 0.0107 ...
 $ Volts_7  : num  3.33185 3.33122 0.01258 0.01211 0.00992 ...
 $ Volts_8  : num  3.3222 3.3225 3.3208 3.3236 0.0129 ...
 $ Deg_C_1  : num  20.2 20.2 20.3 20.7 20.8 ...
 $ Photocell: num  2.49 2.49 2.53 2.52 2.5 ...
 $ Motion_9 : num  3.3368 3.3377 3.3361 0.0623 0.06 ...
 $ IsDark   : int  0 0 0 0 0 0 0 0 0 0 ...

## looks like it worked, export this table to text file: "motion_DST_correct_cleaned429_IsDark.txt"
write.table(allmotioncleaned4, "motion_DST_correct_cleaned429_IsDark.txt", sep = "\t", row.names = FALSE, col.names = TRUE)

# try plotting photoperiod for the first couple of weeks, same limits as above on mouse 85:
ggplot(data = allmotioncleaned4, aes(x = DateTime, y = IsDark)) + geom_area(size = 0.25) + theme_minimal() + labs(title = "Motion_4, #85, Cleaned Data") + scale_x_datetime(limits=c(as.POSIXct("2017-12-04 15:36:00"),as.POSIXct("2017-12-17 07:36:00")))

# now try plotting both at the same time; this works pretty well:  (don't like the slope of the lines, but will crop each of these to make figure)

# time period 1 - transition to long photoperiod
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2017-12-04 07:36:00 - 2017-12-18 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2017-12-04 15:36:00"),as.POSIXct("2017-12-18 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank()) + scale_y_continuous(limits = c(0,3.5))

## note this first plot has some data below zero, which is why we have to set the y axis limits

############################# 9/9/2020 ###########################
# keep working on making actograms for fig 7, using mouse 84 motion_4 data, using the above code for first of 3 or 4 two-week sections to show

# the above (1) and below (4) commands draw the activity, photoperiod, remove the axis, draw a red border expanded left and right by 2400 seconds to help frame the plots for cropping, etc.

# time period 2 - while fattening, pre hibernation
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2018-01-02 15:36:00 - 2018-01-16 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2018-01-02 15:36:00"),as.POSIXct("2018-01-16 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank())

# time period 2.5 - added later 
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2018-01-25 15:36:00 - 2018-02-08 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2018-01-25 15:36:00"),as.POSIXct("2018-02-08 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank())

# time period 3 - transition to torpor
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2018-02-23 15:36:00 - 2018-03-09 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2018-02-23 15:36:00"),as.POSIXct("2018-03-09 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank())

# time period 4 - during torpor (low activity - essentially no motion)
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2018-04-06 15:36:00 - 2018-04-20 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2018-04-06 15:36:00"),as.POSIXct("2018-04-20 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank())

# time period 5 - during torpor (motion on circadian cycle, no food consumption)
ggplot() + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = IsDark * 3.5), color = "lightgray", fill = "lightgray") + geom_area(data = allmotioncleaned4, aes(x = DateTime, y = Motion_4), color = "black", size = 0, fill = "black") + labs(title = "Motion_4, #85, Cleaned Data\n2018-05-13 15:36:00 - 2018-05-27 15:36:00") + scale_x_datetime(limits=c(as.POSIXct("2018-05-13 15:36:00"),as.POSIXct("2018-05-27 15:36:00")), expand = expand_scale(add = 2400)) + theme_classic() + theme(panel.background = element_rect(color = "red", size = 1), axis.line = element_blank())

## save each of the above 5 plots as PDFs for cropping to make figure
# open in Photoshop CS6 at 1200 dpi, copy selection 13.250 x 0.500 inches, aligning at top of gray bar, copy to new file to combine.
# combine in Illustrator and draw borders, remove red color, save as pdf and png file.

##### now working on getting data from nest box warming / thermocouple to draw final figure.
# working from datafiles: 2016-04-28.csv and 2016-04-28--08-19-resume.csv; together these have the whole recording with about a 15 minute break starting at 2016-08-19 13:29.
# combine into "2016-04-28 hibernation nest box temp for Husbandry Paper.csv" - some bad date in first 6 data points (~ 3min) of resume - write over as nan's.

## use some commands from 8/25/2020 ##

nbtemp <- read.table("../../../2016-04-28 hibernation nest box temp for Husbandry Paper.csv", sep=",", header=TRUE)  ## read in data
nbtemp$Date.and.Time <- lubridate::ymd_hms(nbtemp$Date.and.Time, tz = "US/Central")   ### have to specify time zone so it converts properly
	Date in ISO8601 format; converting timezone from UTC to "US/Central".

str(nbtemp) ### checks and looks good

## now try plotting, looks like probe 1 was another mouse that didn't hibernate for as long, use probe 2

ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Reference.2.Temperature), color = "red", size = 0.5) + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Probe.2.Temperature), color = "black", size = 0.5)

## this works but have messy data in reference temperature, looks like a few zeros and one -256; set them to NA

nbtemp$Probe.2.Temperature[nbtemp$Probe.2.Temperature <= 2] <- NA
nbtemp$Reference.2.Temperature[nbtemp$Reference.2.Temperature <= 2] <- NA
nbtemp$Probe.2.Temperature[nbtemp$Probe.2.Temperature >= 25] <- NA
nbtemp$Reference.2.Temperature[nbtemp$Reference.2.Temperature >= 25] <- NA

# looks better, get difference between ref temp and nest box:
nbtemp$Difference.2 <- nbtemp$Probe.2.Temperature - nbtemp$Reference.2.Temperature
# plot it
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Difference.2), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(-2,-1,-0.5,0,1,2,3,4,5))
# create copy of this column and clean it up:
nbtemp$Diff.2.Clean <- nbtemp$Difference.2
nbtemp$Diff.2.Clean[nbtemp$Diff.2.Clean <= -0.5] <- NA

# plot again to get rid of tall noise:
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_minimal() + scale_y_continuous(breaks = c(-2,-1,-0.5,0,1,2,3,4,5,5.5), sec.axis = dup_axis())
# (this duplicates the y axis to the right)
# remove points above 5.5
nbtemp$Diff.2.Clean[nbtemp$Diff.2.Clean > 5.5] <- NA

# plot again and this looks good -- write out table to file:
write.table(nbtemp, "../../../nest_box_temperature_table.txt", sep = "\t", row.names = FALSE, col.names = TRUE)

# see if can use awk script to get dates of warming 
awk 'BEGIN{prev_temp = 100; prev_date = "2016-04-28";getline}{if($1 != prev_date && $8 != "NA" && $8 > 2.5 && $8 > prev_temp){print $0; prev_date = $1}{prev_temp = $8}}' nest_box_temperature_table.txt
# some relevant output:
2016-05-20 00:00:09	13	13.875	18	15.375	2.625	2.625
2016-05-21 00:11:55	13	13.5	17.5	14.9375	2.5625	2.5625
2016-05-23 23:59:13	NA	13.625	17.5	14.9375	2.5625	2.5625
2016-05-24 00:10:14	NA	13.75	17.75	15.0625	2.6875	2.6875
2016-05-25 00:01:01	NA	13.875	17.75	15.125	2.625	2.625
2016-05-26 02:01:59	16.25	13.5625	17.5	14.9375	2.5625	2.5625
2016-05-29 05:13:02	6.5	5.875	9.75	7.1875	2.5625	2.5625
2016-06-04 07:30:51	11.5	5.875	9.75	7.1875	2.5625	2.5625
2016-06-11 09:28:31	6.5	6	10	7.375	2.625	2.625
2016-06-19 10:08:49	6.75	6	10	7.3125	2.6875	2.6875
2016-06-30 05:40:35	11	5.875	9.75	7.1875	2.5625	2.5625
2016-07-09 11:52:36	6.5	6.0625	10	7.375	2.625	2.625
2016-07-22 13:24:13	6.5	6.125	10.25	7.5625	2.6875	2.6875
2016-07-23 00:00:02	6.25	6.0625	10.25	7.375	2.875	2.875
2016-08-04 11:40:03	6.25	6.0625	10	7.375	2.625	2.625
2016-08-14 11:32:43	5.25	5.875	9.75	7.125	2.625	2.625
2016-08-20 13:27:25	8.25	7.5	11.25	8.6875	2.5625	2.5625
2016-08-21 00:00:13	8	7.4375	11.5	8.75	2.75	2.75
2016-08-22 00:00:03	8.25	7.5	11.5	8.75	2.75	2.75
2016-08-23 00:10:20	11	12.0625	16	13.4375	2.5625	2.5625
2016-08-24 00:00:36	10	11.125	15.5	12.5	3	3
2016-08-25 00:01:23	10	11.1875	16	12.5	3.5	3.5
2016-08-26 00:00:14	10.25	11.3125	16.25	12.75	3.5	3.5

# this will give me the dates that the cleaned difference in temperature rose above 2.5 degrees, once per day. Will probably manually locate the date and times of arousal and re-entry and get lengths of arousals and torpor bouts that way.
# there are 11 torpor bouts and 10 arousals; one arousal at the first is long, then others are short
# looking at data -- can adjust breaks using: scale_x_datetime(date_breaks = "6 hours"), can specify how often are the breaks, etc. 
# light cycle was ON 07:30, OFF 15:30; could make new column of light/dark to plot light cycle behind the temperature data.

# getting times for beginning and end of torpor bouts from nest box temperature data by hand from "nest_box_temperature_table.txt", put into excel file "Nest_Box_Temp_Analysis.xlsx".
# using 2 degrees as the cutoff (from the "Diff.2.Clean" column)
# using R plots to find the start and end of torpor bouts, then looking in actual data; have 344,702 lines of data so can't just easily scroll through.

# note - too much high-frequency noise to tell any thing from the column of numbers; will estimate from graphs using 

# first bout start (saving this and future plots)
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-21 18:00:00"),as.POSIXct("2016-05-22 00:30:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90))

# first bout stop
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-23 18:00:00"),as.POSIXct("2016-05-24 04:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "first bout stop")

# bout 2 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-25 18:00:00"),as.POSIXct("2016-05-26 18:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 2 start")

# bout 2 stop / bout 3 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-28 23:00:00"),as.POSIXct("2016-05-30 00:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "2nd bout stop, 3rd bout start")

# bout 3 stop / bout 4 start
 ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-06-04 03:00:00"),as.POSIXct("2016-06-05 00:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 3 stop, bout 4 start")

# bout 4 stop / bout 5 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-06-11 06:00:00"),as.POSIXct("2016-06-12 00:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 4 stop, bout 5 start")

# bout 5 stop / bout 6 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-06-19 06:00:00"),as.POSIXct("2016-06-20 00:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 5 stop, bout 6 start")

# bout 6 stop / bout 7 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-06-30 00:00:00"),as.POSIXct("2016-06-30 21:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 6 stop, bout 7 start")

# bout 7 stop / bout 8 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-07-09 08:00:00"),as.POSIXct("2016-07-10 00:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 7 stop, bout 8 start")

# bout 8 stop / bout 9 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-07-22 08:00:00"),as.POSIXct("2016-07-23 8:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 8 stop, bout 9 start")

# bout 9 stop / bout 10 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-08-04 06:00:00"),as.POSIXct("2016-08-05 02:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 9 stop, bout 10 start")

# bout 10 stop / bout 11 start
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-08-14 06:00:00"),as.POSIXct("2016-08-15 04:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 10 stop, bout 11 start")

# bout 11 stop
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-08-20 00:00:00"),as.POSIXct("2016-08-20 23:00:00")),date_breaks = "15 min") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 11 stop")

# make graphs of bout length and arousal length in prism

# make pretty graph of overall temperature recording; here is a good range:
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-15 00:00:00"),as.POSIXct("2016-08-22 14:00:00")),date_breaks = "1 week") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Torpor and Arousal\nNest Box Temperature Differential")

# try smoothing with loess method available in ggplot [geom_smooth(method = "loess")] ... doesn't work with this large of data set (limit is 1000 points)
# will try rolling average instead; use odd number for k for rolling averages to make symmetric
install.packages("zoo")
library(zoo)

# create new column in nbtemp to hold rolling mean -- plotted it and it looks like this is a good balance of reducing noise but not killing peaks; could go smoother if wanted for main figure
nbtemp$smooth <- zoo::rollmean(nbtemp$Diff.2.Clean, k = 9, fill = NA)

# plot the smoothed line & save it
ggplot() + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-15 00:00:00"),as.POSIXct("2016-08-22 14:00:00")),date_breaks = "1 week") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Torpor and Arousal\nNest Box Temperature Differential") + geom_line(data = nbtemp, aes(x = Date.and.Time, y = smooth), color = "black", size = 0.5)

# save table to file, overwriting prev version
write.table(nbtemp, "../../../nest_box_temperature_table.txt", sep = "\t", row.names = FALSE, col.names = TRUE)

# check some different K values for rolling mean; can apply function directly in the ggplot command:
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = zoo::rollmean(Diff.2.Clean, k = 19, fill = NA)), color = "black", size = 0.5) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-08-12 06:00:00"),as.POSIXct("2016-08-15 04:00:00")),date_breaks = "1 day") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "bout 10 stop, bout 11 start") + geom_line(data = nbtemp, aes(x = Date.and.Time, y = smooth), color = "black", size = 0.25)

ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = zoo::rollmean(Diff.2.Clean, k = 9, fill = NA)), color = "black", size = 0.5) + theme_classic() + scale_y_continuous(breaks = c(0,1,2,3,4,5), sec.axis = dup_axis()) + scale_x_datetime(limits=c(as.POSIXct("2016-05-15 00:00:00"),as.POSIXct("2016-08-22 14:00:00")),date_breaks = "1 week") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Torpor and Arousal\nNest Box Temperature Differential")

############# 9/10/2020 ##############
# believe this is all that is needed; will beautify or adjust figures as needed as I finish drafting manuscript.


############# 9/21/2020 #################
# Looking ito Rayleigh test for time of day of hibernation arousals, 
# Use R, install "circular" library as used in PMID 30100666
install.packages("circular")
library("circular")

#use as input data the hours from onset of darkness determined for the Prism plot:
7.50,12.50,14.75,16.75,17.75,13.25,19.50,21.75,19.25,19.25,19.75

# make the circular vector:
x <- circular(c(7.50,12.50,14.75,16.75,17.75,13.25,19.50,21.75,19.25,19.25,19.75), units = "hours")

# run the test:
> rayleigh.test(x)

       Rayleigh Test of Uniformity
       General Unimodal Alternative

Test Statistic:  0.5915
P-value:  0.0176

############# 9/22/2020 #########################
# Making final figures in R --- this is a redo of a lot of them, will try using ggplot instead of hist for most

## gestation length histogram for Figure 3B, having removed out of bound length possibilities from the frequency distribution
# according to the instances they were out of bounds.

# make text file for input into R, with this data:
Length	Occurances
16	9
17	27
18	33
19	25
20	11

gest_len_subtract <- c(rep(16,9),rep(17,27),rep(18,33),rep(19,25),rep(20,11))

# make plot, use single quotes to get double quotes in axis label
fig3B <- ggplot() + geom_histogram(data=as.data.frame(gest_len_subtract), aes(x = gest_len_subtract), stat="count") + theme_classic() + labs(title = "Possible Gestation Lengths", x = "Days", y = 'Frequency of\n\"In Bounds" Occurances') + theme(plot.title = element_text(hjust = 0.5)) + scale_x_discrete(limits=c(15,16,17,18,19,20,21)) + scale_y_discrete(limits=c(0,5,10,15,20,25,30,35))

# save plot to file
ggsave(plot = fig3B, width = 3, height = 2.5, dpi = 1200, filename = "Fig_3B.pdf")

## histogram of litter size for Fig 3C

# read in litter sizes
litter_size <- as.data.frame(read.table("litter-size.txt"))
# make plot
fig3C <- ggplot() + geom_histogram(data=litter_size, aes(x = V1), stat="count") + theme_classic() + labs(title = "Litter Size by Frequency", x = "Weaned Pups per Litter", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_discrete(limits=c(0:7)) + scale_y_discrete(limits=c(0:8))
# save plot
ggsave(plot = fig3C, width = 3, height = 2.5, dpi = 1200, filename = "Fig_3C.pdf")

## histogram of sex ration (fraction male) for figure 3D
# get data
frac_male <- as.vector(read.table("fraction_male.txt"))
# make plot
fig3D <- ggplot() + geom_histogram(data=frac_male, aes(x = V1), binwidth=0.1) + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\n(Fraction Male)", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5))
# save plot
ggsave(plot = fig3D, width = 3, height = 2.5, dpi = 1200, filename = "Fig_3D.pdf")

## make supplemental figure plots of simulated histograms -- have to redo simulations from 7/24 simulation to get those histograms!

litter_size <- as.vector(read.table("litter-size.txt"))

# simulate 10 million sets of 32 litters with my litter size distribution
size <- as.vector(litter_size$V1)  # make vector of litter_sizes
matrix_out <-matrix(ncol=10000000,nrow=32)
system.time(for (i in 1:32) {matrix_out[i,] <- rbinom(10000000,size[i],0.5)})

# now need to divide by litter size to get fraction male
matrix_out_fraction <- matrix_out / size  
max(matrix_out_fraction)  

# transpose for row counting  -- not necessary here but already done
matrix_out_fraction <- t(matrix_out_fraction)

#unlist them, make data frame
fraction_05_unlist <- as.data.frame(unlist(matrix_out_fraction))

#plot using ggplot
figS1B <- ggplot() + geom_histogram(data=fraction_05_unlist, aes(x = V1), binwidth=0.1) + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\nfrom 10M Simulated Sets of 32 Litters", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5))
# save plot
ggsave(plot = figS1B, width = 3, height = 2.5, dpi = 1200, filename = "Fig_S1B.pdf")

### this does not look as good as what's in the supplement -- looks like I have a problem with the structure of my
### data (didn't unlist?)  will just leave the others as they are in the supplement

### thinking about motion data quantification for Fig 7: would be better to graph all motion data (not averaged over
### the 3 or 4 day (usually) periods of food consumption.

################# 9/23/2020 #########################
# Doing some work on PIR motion data from the animals....

# show percent of 24 hour day active, and percent of daily activity occuring during light cycle?
# scatter plots of these not informative

# making pretty version of nest box temperature differential plot -- load data from work done on 9/9/2020.
nbtemp <- read.table("nest_box_temperature_table.txt", header=TRUE, sep="\t")
# need to convert to appropriate time format
library(lubridate)
nbtemp$Date.and.Time <- lubridate::ymd_hms(nbtemp$Date.and.Time, tz = "US/Central")
# plot it
ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "red", size = 0.25) + theme_minimal() + scale_y_continuous(breaks = c(-2,-1,-0.5,0,1,2,3,4,5,5.5), sec.axis = dup_axis())

# work on making the plot pretty and save directly  ... note moving title down vertically below standard
fig8a <- ggplot() + geom_line(data = nbtemp, aes(x = Date.and.Time, y = Diff.2.Clean), color = "black", size = 0.1) + theme_minimal() + scale_y_continuous(limit=c(-1,6), breaks = c(0,1,2,3,4,5,6)) + theme_classic() + labs(x = "Month", y = "Nest Box Heating (ºC)", title = "Torpor and Arousal During Hibernation at 7º C", subtitle = "Nest Box Temperature Differential") + theme(plot.title = element_text(hjust = 0.5, vjust = -5, face = "bold"), plot.subtitle = element_text(hjust = 0.5, vjust = -5, face = "bold"), axis.title.x = element_text(face = "bold"), axis.title.y = element_text(face = "bold"))

ggsave(plot = fig8a, units = "in", width = 9, height = 3.5, dpi = 1200, device = "png", filename = "Fig_8A.png")
# looks good

### make plots for supplemental figure of breeder hibernation experiment
# redo work from 9/2/2020, but fill under the lines on the plots
# read in table of cleaned motion data:
allmotionclean <- read.table("motion_DST_correct_cleaned429.txt", header=TRUE, sep="\t")
# convert DateTime to correct date format with lubridate
allmotionclean$DateTime <- ymd_hms(allmotionclean$DateTime, tz = "US/Central")


m2 <- ggplot(data = allmotionclean, aes(x = DateTime, y = Motion_2)) + geom_area(size = 0.1, color = "black", fill = "black") + theme_classic() + labs(title = "Motion_2", x = "Months", y = "Activity (Signal Voltage)")
m3 <- ggplot(data = allmotionclean, aes(x = DateTime, y = Motion_3)) + geom_area(size = 0.1, color = "black", fill = "black") + theme_classic() + labs(title = "Motion_3", x = "Months", y = "Activity (Signal Voltage)")
m4 <- ggplot(data = allmotionclean, aes(x = DateTime, y = Motion_4)) + geom_area(size = 0.1, color = "black", fill = "black") + theme_classic() + labs(title = "Motion_4", x = "Months", y = "Activity (Signal Voltage)")
m9 <- ggplot(data = allmotionclean, aes(x = DateTime, y = Motion_9)) + geom_area(size = 0.1, color = "black", fill = "black") + theme_classic() + labs(title = "Motion_9", x = "Months", y = "Activity (Signal Voltage)")

ggsave(plot = m2, units = "in", width = 6, height = 2, dpi = 600, device = "png", filename = "Motion2.png")
ggsave(plot = m3, units = "in", width = 6, height = 2, dpi = 600, device = "png", filename = "Motion3.png")
ggsave(plot = m4, units = "in", width = 6, height = 2, dpi = 600, device = "png", filename = "Motion4.png")
ggsave(plot = m5, units = "in", width = 6, height = 2, dpi = 600, device = "png", filename = "Motion5.png")
ggsave(plot = m9, units = "in", width = 6, height = 2, dpi = 600, device = "png", filename = "Motion9.png")

# to do:
days elapsed, activity on breeder hib supplement


last pass on writing, need protocol & grant numbers, address comments by Ethan

wait on fixing tables until see what format needed for submission

################### 9/24/2020 ####################
# note: days elapsed for all 5 "breeder hibernation experiment" weight data sets are the same -- no shifted data points
# cleaning up motion data a little more -- will have to do much more of this if want to do additional analysis on these data.

# 106 last weigh-in was 4/13, on day 133 - remove motion after this in Prism for supplemental figure graphs
# 104 appears to have bad motion sensor data at end of run .. 100% of day active, conflicting with us finding the animal torpid
# checking dates of first time 104 was 100% active: 145, 148-150 --- again almost 100% 158 - 162 --- ramps back up to 100% starting 175
# compare to days found torpid: torpid on day 140, not torpid on day 147, torpid on day 154 to end (189)
# I believe the first large burst of activity during torpor (days 145-150) could be real but probably bad sensor .. days found torpid excludes the second two runs of high activity. 
# 104 is channel 3, plot parts of this area in R to see what's going on for good measure, for example:
ggplot(data = allmotionclean, aes(x = DateTime, y = Motion_3)) + geom_area(size = 0.1, color = "black", fill = "black") + theme_classic() + labs(title = "Motion_3", x = "Months", y = "Activity (Signal Voltage)") + scale_x_datetime(limits=c(as.POSIXct("2018-05-03 00:00:00"),as.POSIXct("2018-05-18 23:59:59")), date_breaks = "1 day")

# I'm going to exclude this data from the first time it ramps up to 100% activity starting on day 143 when recording resumed.
# i.e. exclude day 143 data to end of experiment.

################# 9/25/2020 ###################
#updating map of Bolton Flats WMA to be wider (look better) in figure
# original:
stamen_map_1 <- get_stamenmap(bbox = c(left = -71.67, bottom = 42.445, right = -71.62, top = 42.485), zoom = 14, maptype = "terrain")
ggmap(stamen_map_1)

#wider
stamen_map_wide <- get_stamenmap(bbox = c(left = -71.68, bottom = 42.445, right = -71.6, top = 42.485), zoom = 14, maptype = "terrain")
ggmap(stamen_map_wide) + labs(x = "Longitude", y = "Latitude") + theme(plot.margin = margin(4, 6, 4, 4, "mm"), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))



############# REVISIONS ####################

################ 12/18/2020 ######################

## Used brew to get a tool for .svg to .png file conversion and it updated my R version.
## now at:   R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"

## will have to install some libraries:
install.packages("ggplot")
install.packages("ggmap")
install.packages(“tidyr”)
install.packages("dplyr")
library("ggplot2")





### adjusting some figures for the reviewers -- ** start from 9/22/2020 commands **
# try figure 3D first; reviewer wants ticks at 0.1 intervals.

## histogram of sex ration (fraction male) for FIGURE 3D
# get data
frac_male <- as.vector(read.table("fraction_male.txt"))
# work on adjusting plot and x axis, note that histogram uses continuous scale, so specify breaks as in this command:
ggplot() + geom_histogram(data=frac_male, aes(x = V1), binwidth=0.1) + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\n(Fraction Male)", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

# now write out
fig3D_revised <- ggplot() + geom_histogram(data=frac_male, aes(x = V1), binwidth=0.1) + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\n(Fraction Male)", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

# save plot
ggsave(plot = fig3D_revised, width = 3, height = 2.5, dpi = 1200, filename = "Fig_3D_revised.pdf")

# this is ok, but leading zeros are so close to previous number that it's hard to read. See if can adjust font somehow

# the following works well to rotate the text and align the left side of the rotated text to the tick; however, this also moves the x axis up vertically
ggplot() + geom_histogram(data=frac_male, aes(x = V1), binwidth=0.1) + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\n(Fraction Male)", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 315, hjust=0)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

# try making text smaller, and not rotated --- this works, use this for "final" figure 3D (revised)
fig3D_revised <- ggplot() + geom_histogram(data=frac_male, aes(x = V1), binwidth=0.1, color="white") + theme_classic() + labs(title = "Histogram of Litter Sex Ratios\n(Fraction Male)", x = "Sex Ratio (Fraction Male)", y = "Number of Litters") + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(size=8)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

ggsave(plot = fig3D_revised, width = 3, height = 2.5, dpi = 1200, filename = "Fig_3D_revised.pdf")


## Now work on histograms in FIGURE S1

# FIGURE S1A - Histogram of possible gestation lengths: originally plotted using hist() -- see 8/1/2020 & 8/26/2020, will need to figure out how to do it using ggplot2

# load data into R
gest_max_min <- read.table("./gest_length/gest_length_bounds.txt", header=TRUE)
# make data frame, note this is too wide, but non-issue for what I want to do
x <- data.frame(matrix(ncol = 39, nrow = 37))   # 
# fill in numbers of possible days for each range, pad with NA's at end
for (i in 1:nrow(gest_max_min)) {x[i,] <- c(seq(gest_max_min$Min[i],gest_max_min$Max[i]),rep(NA,39-length(seq(gest_max_min$Min[i],gest_max_min$Max[i]))))}
# make list from data frame for use as histogram input, use "na.omit" to get rid of NAs 
S1A_data <- na.omit(as.data.frame(unlist(x)))
# rename column
colnames(S1A_data) <- "days"

# figure out how to plot nicely - the below works well enough and will match main figures
ggplot() + geom_histogram(data=S1A_data, aes(x = days), binwidth=1) + theme_classic() + labs(title = "Histogram of Possible Gestation Lengths", x = "Possible Days Gestation", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0:40)) + + geom_histogram(data=gest_, aes(x = days), binwidth=1)

# now get the data for the pink and blue boundaries and figure out how to overlay them ... the following works well enough:
ggplot() + geom_histogram(data=S1A_data, aes(x = days), binwidth=1, color = "white") + theme_classic() + labs(title = "Histogram of Possible Gestation Lengths", x = "Possible Days Gestation", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(seq(from = 0, to = 40, by = 2))) + geom_histogram(data=gest_max_min, aes(x = Max), binwidth=1, fill = alpha("pink",0.7), color = "white") + geom_histogram(data=gest_max_min, aes(x = Min), binwidth=1, fill = alpha("lightblue", 0.7), color = "white")

# settle on the following (note ticks by twos seems like best option), write out and save file at a larger size:

figS1A_revised <- ggplot() + geom_histogram(data=S1A_data, aes(x = days), binwidth=1, color = "white") + theme_classic() + labs(title = "Histogram of Possible Gestation Lengths", x = "Possible Days Gestation", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(seq(from = 0, to = 40, by = 2))) + geom_histogram(data=gest_max_min, aes(x = Max), binwidth=1, fill = alpha("pink",0.7), color = "white") + geom_histogram(data=gest_max_min, aes(x = Min), binwidth=1, fill = alpha("lightblue", 0.7), color = "white")

ggsave(plot = figS1A_revised, width = 6, height = 5, dpi = 1200, filename = "Fig_S1A_revised.pdf")

# try plum1 & lightblue colors to better show overlap:

figS1A_revised2 <- ggplot() + geom_histogram(data=S1A_data, aes(x = days), binwidth=1, color = "white") + theme_classic() + labs(title = "Histogram of Possible Gestation Lengths", x = "Possible Days Gestation", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(seq(from = 0, to = 40, by = 2))) + geom_histogram(data=gest_max_min, aes(x = Max), binwidth=1, fill = alpha("plum1", 0.7), color = "white") + geom_histogram(data=gest_max_min, aes(x = Min), binwidth=1, fill = alpha("lightblue", 0.6), color = "white") + scale_y_continuous(breaks=c(seq(0,40,2)))

ggsave(plot = figS1A_revised2, width = 6, height = 5, dpi = 1200, filename = "Fig_S1A_revised2.pdf")

## FIGURE S1B-S1F - Simulated Data Histograms and Histogram of Sizes of Single-Sex Litters - will have to redo simulation, see 7/24/2020

# read in litter sizes
litter_size <- as.data.frame(read.table("litter-size.txt"))

# simulate 10 million sets of 32 litters with my litter size distribution, ratio = 0.5
size <- as.vector(litter_size$V1)  # make vector of litter_sizes
matrix_out <-matrix(ncol=10000000,nrow=32)
system.time(for (i in 1:32) {matrix_out[i,] <- rbinom(10000000,size[i],0.5)})

# now need to divide by litter size to get fraction male
matrix_out_fraction <- matrix_out / size  
max(matrix_out_fraction)   #make sure equals 1

# use "matrix_out_fraction" -- this simulated data set underlies the histograms of fraction male in Fig S1
# convert to single column in data frame for use in ggplot histogram,  c() will convert matrix to vector, this was fast
sim_frac_male_0.5 <- as.data.frame(c(matrix_out_fraction))
# check structure - looks good
str(sim_frac_male_0.5)
# rename column in data frame
colnames(sim_frac_male_0.5) <- "fracmale0.5"

ggplot() + geom_histogram(data=sim_frac_male_0.5, aes(x = fracmale0.5), binwidth=0.1, color = "white") + theme_classic() + labs(title = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.5 of Male", x = "Fraction Male, n = 10M * 32 Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) # not working, see note below

## getting the following error.... Error: vector memory exhausted (limit reached?), added "R_MAX_VSIZE=100Gb" to first line of .Renviron, had to restart R, but this helps -- making the plot now uses about 28Gb memory

# going for smaller binwidth, which looks great once saved:
figS1B <- ggplot() + geom_histogram(data=sim_frac_male_0.5, aes(x = fracmale0.5), binwidth=0.05, color = "white") + theme_classic() + labs(title = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.5 of Male", x = "Fraction Male, n = 10M * 32 Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5))

ggsave(plot = figS1B, width = 6, height = 5, dpi = 1200, filename = "Fig_S1B_revised.pdf") # still need more x axis ticks

# now need to put more tick marks on the x axis for the reviewer, this is probably good enough; there is no easy way to 
figS1B <- ggplot() + geom_histogram(data=sim_frac_male_0.5, aes(x = fracmale0.5), binwidth=0.05, color = "white") + theme_classic() + labs(title = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.5 of Male", x = "Fraction Male, n = 10M * 32 Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

ggsave(plot = figS1B, width = 6, height = 5, dpi = 1200, filename = "Fig_S1B_revised2.pdf")

### work continues 12/19/2020, make revised histogram for p=0.6615 sex ratio ###

# continue to repeat prev work to simulate 10 million sets of 32 litters with my litter size distribution
matrix_out_066 <-matrix(ncol=10000000,nrow=32)
system.time(for (i in 1:32) {matrix_out_066[i,] <- rbinom(10000000,size[i],0.6615385)})

# now need to divide by litter size to get fraction male
matrix_out_066_fraction <- matrix_out_066 / size  
max(matrix_out_066_fraction)  
[1] 1

# convert to single column in data frame for use in ggplot histogram,  c() will convert matrix to vector, this was fast
sim_frac_male_0.66 <- as.data.frame(c(matrix_out_066_fraction))
# check structure - looks good
str(sim_frac_male_0.66)
# rename column in data frame
colnames(sim_frac_male_0.66) <- "fracmale0.66"

figS1C <- ggplot() + geom_histogram(data=sim_frac_male_0.66, aes(x = fracmale0.66), binwidth=0.05, color = "white") + theme_classic() + labs(title = "Histogram of 10 Million Simulated Sets of 32 Litters\np=0.6615 of Male", x = "Fraction Male, n = 10M * 32 Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

ggsave(plot = figS1C, width = 6, height = 5, dpi = 1200, filename = "Fig_S1C_revised.pdf")

## FIGURE S1D-E: read in tables of numbers of single-sex litters

dist_05 <- read.table("distribution_10M_05.txt", header = TRUE)
dist_066 <- read.table("distribution_10M_066.txt", header = TRUE)

# make data frame for placing marker at 19 litters:
x <- 19
y <- 0
dot_at_19 <- data.frame(x,y)

dot_at_19
   x y
1 19 0

# want commas in axis labels, load library and use "label=comma" in scale command: 
library(scales)

# set same axes limits on these to make them comparable.

figS1D <- ggplot() + geom_histogram(data=dist_05, aes(x = x), binwidth=1, color = "white") + theme_classic() + labs(title = "Number of Single-Sex Litters per 31 Simulated Litters at p=0.6615 for Males\nDistribution from 10 Million Simulated Sets of 32 Litters", x = "Number of Single-Sex Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0:22), limits = c(0,22)) + scale_y_continuous(label=comma, limits = c(0, 2500000)) + geom_point(dot_at_19, mapping = aes(x = x, y = y), color = "red", size = 5)

ggsave(plot = figS1D, width = 8, height = 5, dpi = 1200, filename = "Fig_S1D_revised.pdf")

figS1E <- ggplot() + geom_histogram(data=dist_066, aes(x = x), binwidth=1, color = "white") + theme_classic() + labs(title = "Number of Single-Sex Litters per 31 Simulated Litters at p=0.6615 for Males\nDistribution from 10 Million Simulated Sets of 3s Litters", x = "Number of Single-Sex Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0:22), limits = c(0,22)) + scale_y_continuous(label=comma, limits = c(0, 2500000)) + geom_point(dot_at_19, mapping = aes(x = x, y = y), color = "red", size = 5)

ggsave(plot = figS1E, width = 8, height = 5, dpi = 1200, filename = "Fig_S1E_revised.pdf")


## FIGURE S1F: plot histogram of actual data 
# read into R to plot histogram and get 
litter_size_all_M_or_F <- as.vector(read.table("litter-size_all-M-or-F.txt"))

figS1F <- ggplot() + geom_histogram(data=litter_size_all_M_or_F, aes(x = V1), binwidth=1, color = "white") + theme_classic() + labs(title = "Histogram: Size of Single-Sex Litters", x = "Number of Weaned Pups per Litter, n = 19 Litters", y = "Frequency") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_continuous(breaks = c(0:7), limits = c(0,7)) + scale_y_continuous(breaks = c(0:7))

# save plot
ggsave(plot = figS1F, width = 6, height = 5, dpi = 1200, filename = "Fig_S1F_revised.pdf")

############### 12/22/2020 ##################

# redoing the regression analysis in R to remove the interaction between temperature and photoperiod
# see old work from 8/28/2020

# Import into R:
> pre_hib_food_vs_weight <- read.table("../glm_hib_experiment/pre_hib_food_vs_wt.txt", header = TRUE)


# 
lm_pre_hib_food_wt <- lm(formula = Food ~ Weight*Temp + Photoperiod + Location + Litter, pre_hib_food_vs_weight)
summary(lm_pre_hib_food_wt)




